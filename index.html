<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link
			rel="stylesheet"
			href="https://unpkg.com/purecss@1.0.1/build/pure-min.css"
			integrity="sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47"
			crossorigin="anonymous"
		/>
		<link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css" />
		<link
			rel="stylesheet"
			href="https://use.fontawesome.com/releases/v5.0.12/css/all.css"
			integrity="sha384-G0fIWCsCzJIMAVNQPfjH08cyYaUtMwjJwqiRKxxE/rx96Uroj1BtIQ6MLJuheaO9"
			crossorigin="anonymous"
		/>
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link
			href="https://fonts.googleapis.com/css2?family=Barlow:wght@300;400;600&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css?family=Open+Sans:400|Roboto:900,400"
			rel="stylesheet"
		/>
		<link rel="stylesheet" href="./global.css" />
		<link rel="icon" href="./favicon.png" />
		<meta http-equiv="content-security-policy" content="">
		<link href="./_app/immutable/assets/_layout-7881511e.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Social-8d9510f7.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Footer-6b856700.css" rel="stylesheet">
		<link href="./_app/immutable/assets/_page-2e0fe5d1.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Intro-3c2639d7.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/start-6e369c95.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index-a0c4dc22.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons-c771b6a0.js">
		<link rel="modulepreload" href="./_app/immutable/components/layout.svelte-07d582e8.js">
		<link rel="modulepreload" href="./_app/immutable/modules/pages/_layout.js-9cbb603b.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_layout-fca24c55.js">
		<link rel="modulepreload" href="./_app/immutable/components/pages/(base)/_layout.svelte-cfbb176b.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Social-4c45f8ee.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Footer-fafe335b.js">
		<link rel="modulepreload" href="./_app/immutable/modules/pages/(base)/_layout.js-e992bf42.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_layout-da46b06b.js">
		<link rel="modulepreload" href="./_app/immutable/components/pages/(base)/_page.svelte-6941d9ce.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Intro-742791ac.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Links-9ec14a0b.js">
		<link rel="modulepreload" href="./_app/immutable/modules/pages/(base)/_page.js-08abca11.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/js-yaml-38530ef5.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/publist-1042989d.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_page-9e01003b.js">
	</head>
	<body>
		<div>


<div class="pure-g" id="main-container"><div id="sidebar" class="pure-u-1 pure-u-md-1-4"><div id="padded-sidebar" class="svelte-ogw1pb"><a href="/"><img width="180px" src="images/profile.png" alt="profile" class="svelte-ogw1pb"></a>
		<h1 id="name" class="svelte-ogw1pb"><span class="color svelte-ogw1pb">Ángel </span>
			<br>
			<span class="color red svelte-ogw1pb">Alex</span>
			<span class="color svelte-ogw1pb">ander</span>
			<br>
			<span class="color red svelte-ogw1pb">Cabrera</span></h1>
		<div id="social">
	<a href="mailto:cabrera@cmu.edu"><h3 class="svelte-k1wkez"><i class="fas fa-envelope"></i>   cabrera@cmu.edu</h3></a>
	<a href="https://twitter.com/a_a_cabrera"><h3 class="svelte-k1wkez"><i class="fab fa-twitter social-icon"></i>   @a_a_cabrera</h3></a>
		<a href="https://cabreraalex.medium.com/"><h3 class="svelte-k1wkez"><i class="fab fa-medium-m"></i>   Blog</h3></a>
	<a href="https://scholar.google.com/citations?user=r89SDm0AAAAJ&hl=en"><h3 class="svelte-k1wkez"><i class="fas fa-graduation-cap"></i>  Google Scholar</h3></a>
	<a href="https://github.com/cabreraalex"><h3 class="svelte-k1wkez"><i class="fab fa-github"></i>   GitHub</h3></a>
</div>
		<a href="/cv"><button class="cv">CV (web)</button></a>
		<a href="/cv.pdf" rel="external"><button class="cv">CV (pdf)</button></a></div>
</div>
	<div id="content" class="pure-u-1 pure-u-md-3-4"><div id="padded-content"><div id="intro"><h2 class="header svelte-6075h1">Hi! You can call me <span class="name">Alex</span></h2>
		<p class="svelte-7wqlfe">I am a PhD student in the
	<a href="https://hcii.cmu.edu/">Human-Computer Interaction Institute (HCII) </a>
	at Carnegie Mellon University, advised by
	<a href="http://perer.org">Adam Perer</a>
	and
	<a href="http://www.cs.cmu.edu/~jasonh/">Jason Hong.</a>
	I work on human-centered AI, specifically in applying techniques from HCI and visualization to help
	people better understand and improve their machine learning models. I am supported by an
	<a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a>
	and have spent time at
	
	Apple AI/ML, Microsoft Research, and Google.
	
	</p>







</div>
	<div id="news" class="sect"><div class="inline svelte-6075h1"><h2 class="header svelte-6075h1">News</h2>
			<p><a class="right-all" href="/news">see all</a></p></div>
		<hr>
		<div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">March 6, 2023</p>
				<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->Zeno was selected for the <a href ="https://foundation.mozilla.org/en/blog/auditing-ai-announcing-the-2023-mozilla-technology-fund-cohort/">Mozilla Technology Fund on tools for auditing AI systems</a>.<!-- HTML_TAG_END --></p>
			</div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">February 1, 2023</p>
				<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->We announced <a href="https://zenoml.com">&#128160; Zeno</a>, a general-purpose ML evaluation framework.<!-- HTML_TAG_END --></p>
			</div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">May 1, 2022</p>
				<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->Presenting <a href='https://dl.acm.org/doi/10.1145/3491102.3502102'>Symphony</a> at CHI'22 in New Orleans &#127927;<!-- HTML_TAG_END --></p>
			</div></div>
	<div id="pubs" class="sect"><div class="inline svelte-6075h1"><h2 class="header svelte-6075h1">Refereed Publications</h2></div>
		<hr>
		<div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/zeno"><div style="background-image: url(images/zeno.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">CHI'23</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/zeno"><h4 class="paper-title">Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://ericafu.me/'>Erica Fu</a>, <a class=' author' href='https://www.donnybertucci.com/'>Donald Bertucci</a>, <a class=' author' href='https://www.thecoalalab.com/kenholstein'>Kenneth Holstein</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a>, <a class=' author' href='http://perer.org'>Adam Perer</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3581268" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://doi.org/10.1145/3544548.3581268"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	<a href="http://zenoml.com"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Website</p></button></a>
	
	
	
	<a href="https://github.com/zeno-ml/zeno"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="/paper/zeno"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/behavior"><div style="background-image: url(images/behavior.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">CSCW'23</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/behavior"><h4 class="paper-title">Improving Human-AI Collaboration with Descriptions of AI Behavior</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3579612" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3579612"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="/paper/behavior"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/aiffinity"><div style="background-image: url(images/aiffinity.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">TOCHI'22</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/aiffinity"><h4 class="paper-title">What Did My AI Learn? How Data Scientists Make Sense of Model Behavior</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://homes.cs.washington.edu/~marcotcr/'>Marco Tulio Ribeiro</a>, <a class=' author' href='http://bongshiny.com/'>Bongshin Lee</a>, <a class=' author' href='https://www.microsoft.com/en-us/research/people/rdeline/'>Rob DeLine</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='https://www.microsoft.com/en-us/research/people/sdrucker/'>Steven M. Drucker</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3542921" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3542921"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="/paper/aiffinity"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/symphony"><div style="background-image: url(images/symphony.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">CHI'22</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/symphony"><h4 class="paper-title">Symphony: Composing Interactive Interfaces for Machine Learning</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera*</a>, <a class=' author' href='https://a13x.io/'>Alex Bäuerle*</a>, <a class=' author' href='https://fredhohman.com/'>Fred Hohman</a>, <a class=' author' href='javascript:void(0);'>Megan Maher</a>, <a class=' author' href='javascript:void(0);'>David Koski</a>, <a class=' author' href='javascript:void(0);'>Xavier Suau</a>, <a class=' author' href='https://www.barik.net/'>Titus Barik</a>, <a class=' author' href='https://www.domoritz.de/'>Dominik Moritz</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3491102.3502102" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3491102.3502102"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	<a href="https://www.youtube.com/watch?v=0Q3wIh3AiPs"><button class="entry-link"><i class="fab fa-youtube"></i>
				<p>Video</p></button></a>
	
	
	<a href="/paper/symphony"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/covidcast"><div style="background-image: url(images/covidcast.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">PNAS'21</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/covidcast"><h4 class="paper-title">An open repository of real-time COVID-19 indicators</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='javascript:void(0);'>Alex Reinhart</a>, <a class=' author' href='javascript:void(0);'>Logan Brooks</a>, <a class=' author' href='javascript:void(0);'>Maria Jahja</a>, <a class=' author' href='javascript:void(0);'>Aaron Rumack</a>, <a class=' author' href='javascript:void(0);'>Jingjing Tang</a>, <a class='me author' href='javascript:void(0);'>[et al, including Ángel Alexander Cabrera]</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://www.pnas.org/content/pnas/118/51/e2111452118.full.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://www.pnas.org/doi/10.1073/pnas.2111452118"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	<a href="https://delphi.cmu.edu/covidcast/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Website</p></button></a>
	
	
	
	<a href="https://github.com/cmu-delphi/www-covidcast"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="/paper/covidcast"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/deblinder"><div style="background-image: url(images/deblinder.jpg)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">CSCW'21</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/deblinder"><h4 class="paper-title">Discovering and Validating AI Errors With Crowdsourced Failure Reports</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='javascript:void(0);'>Abraham Druck</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a>, <a class=' author' href='http://perer.org'>Adam Perer</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://cabreraalex.com/deblinder.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3479569"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="/paper/deblinder"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/expo"><div style="background-image: url(images/expo.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">NeurIPS'20</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/expo"><h4 class="paper-title">Regularizing Black-box Models for Improved Interpretability</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://www.cs.cmu.edu/~mshediva/'>Maruan Al-Shedivat</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org/'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~epxing/'>Eric Xing</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.5555/3495724.3496607" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.5555/3495724.3496607"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	<a href="https://github.com/GDPlumb/ExpO"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="/paper/expo"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/confusion"><div style="background-image: url(images/representations.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">CSCW'20</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/confusion"><h4 class="paper-title">Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class=' author' href='http://shift-3.com/'>Haojian Jin</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='https://haiyizhu.com/'>Haiyi Zhu</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3415224"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="/paper/confusion"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/fairvis"><div style="background-image: url(images/fairvis.png)" class="thumb" alt="teaser"></div></a>
					<div><p class="venue">VIS'19</p>
					</div></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/fairvis"><h4 class="paper-title">FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning</h4></a>
						<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://willepperson.com'>Will Epperson</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://arxiv.org/abs/1904.05419" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://ieeexplore.ieee.org/document/8986948"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	<a href="https://poloclub.github.io/FairVis/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Website</p></button></a>
	<a href="https://medium.com/@cabreraalex/fairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f"><button class="entry-link"><i class="fab fa-medium"></i>
				<p>Blog</p></button></a>
	
	<a href="https://vimeo.com/showcase/6524122/video/368702211"><button class="entry-link"><i class="fab fa-youtube"></i>
				<p>Video</p></button></a>
	<a href="https://github.com/poloclub/FairVis"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="/paper/fairvis"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div></div>
	<div id="pubs" class="sect"><div class="inline svelte-6075h1"><h2 class="header svelte-6075h1">Workshops, Demos, Posters, and Preprints</h2></div>
		<hr>
		<div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/spotcheck"><div style="background-image: url(images/spotcheck.png)" class="thumb" alt="teaser"></div></a>
					<p class="venue">Workshop, ICML'22</p></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/spotcheck"><h4 class="paper-title">Evaluating Systemic Error Detection Methods using Synthetic Images</h4></a>
						<p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://njohnson99.github.io/'>Nari Johnson</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://homes.cs.washington.edu/~marcotcr/'>Marco Tulio Ribeiro</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://arxiv.org/pdf/2207.04104.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	
	
	
	
	
	<a href="/paper/spotcheck"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/publics"><div style="background-image: url(images/publics-in-loop.png)" class="thumb" alt="teaser"></div></a>
					<p class="venue">Workshop, CHI'20</p></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/publics"><h4 class="paper-title">"Public(s)-in-the-Loop": Facilitating Deliberation of Algorithmic Decisions in Contentious Public Policy Domains</h4></a>
						<p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://www.andrew.cmu.edu/user/hongs/files/20_chi_workshop_publics.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	
	<a href="http://fair-ai.owlstown.com/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Workshop</p></button></a>
	
	
	
	<a href="/paper/publics"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/subgroup-gen"><div style="background-image: url(images/iclr.png)" class="thumb" alt="teaser"></div></a>
					<p class="venue">Workshop, ICLR'19</p></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/subgroup-gen"><h4 class="paper-title">Discovery of Intersectional Bias in Machine Learning Using Automatic Subgroup Generation</h4></a>
						<p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_3.pdf" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	
	<a href="https://debug-ml-iclr2019.github.io/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Workshop</p></button></a>
	
	
	
	<a href="/paper/subgroup-gen"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-6075h1"><a href="/paper/interactive-classification"><div style="background-image: url(images/interactive.png)" class="thumb" alt="teaser"></div></a>
					<p class="venue">Demo, CVPR'18</p></div>
				<div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/interactive-classification"><h4 class="paper-title">Interactive Classification for Deep Learning Interpretation</h4></a>
						<p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jlin.xyz'>Jason Lin</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END -->
						</p></div>
					<div class="buttons"><a href="https://arxiv.org/abs/1806.05660" rel="external"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	<a href="https://cabreraalex.github.io/interactive-classification"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Website</p></button></a>
	
	
	<a href="https://www.youtube.com/watch?v=llub5GcOF6w"><button class="entry-link"><i class="fab fa-youtube"></i>
				<p>Video</p></button></a>
	<a href="https://github.com/poloclub/interactive-classification"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="/paper/interactive-classification"><button class="entry-link"><i class="fas fa-info-circle"></i>
			<p>Details</p></button></a></div></div>
			</div></div>
</div>
		<div class="footer svelte-1ynsxf6"><p id="copyright">© 2022 Ángel Alexander Cabrera - Made with
		<a href="https://svelte.dev">SvelteKit</a></p>
</div></div></div>


		<script type="module" data-sveltekit-hydrate="sl5dze">
			import { start } from "./_app/immutable/start-6e369c95.js";

			start({
				env: {},
				hydrate: {
					status: 200,
					error: null,
					node_ids: [0, 2, 4],
					params: {},
					routeId: "/(base)",
					data: (function(a){return [a,a,a]}(null)),
					form: null
				},
				paths: {"base":"","assets":""},
				target: document.querySelector('[data-sveltekit-hydrate="sl5dze"]').parentNode,
				trailing_slash: "never"
			});
		</script>
	<script type="application/json" data-sveltekit-fetched data-url="/news.yml">{"status":200,"statusText":"","headers":{},"body":"- date: 'March 6, 2023'\n  news: Zeno was selected for the \u003Ca href =\"https://foundation.mozilla.org/en/blog/auditing-ai-announcing-the-2023-mozilla-technology-fund-cohort/\">Mozilla Technology Fund on tools for auditing AI systems\u003C/a>.\n- date: 'February 1, 2023'\n  news: We announced \u003Ca href=\"https://zenoml.com\">&#128160; Zeno\u003C/a>, a general-purpose ML evaluation framework.\n- date: 'May 1, 2022'\n  news: Presenting \u003Ca href='https://dl.acm.org/doi/10.1145/3491102.3502102'>Symphony\u003C/a> at CHI'22 in New Orleans &#127927;\n- date: 'May 17, 2021'\n  news: First week at &#127822;!\n- date: 'May 18, 2020'\n  news: >-\n    Excited to spend the summer doing a ~virtual~ internship at Microsoft\n    Research with \u003Ca\n    href='https://www.microsoft.com/en-us/research/people/sdrucker/'>Steven\n    Drucker\u003C/a> at the \u003Ca\n    href='https://www.microsoft.com/en-us/research/group/vida/'>VIDA group.\u003C/a>\n- date: 'April 23, 2020'\n  news: >-\n    Our system for visualizing indicators of COVID symptoms \u003Ca\n    href='https://covidcast.cmu.edu/'>is live!\u003C/a>\n- date: 'March 5, 2020'\n  news: >-\n    Thanks to the Data Stories podcast for having Yongsu Ahn and me on their\n    show to talk about \u003Ca\n    href='https://datastori.es/156-fairness-in-machine-learning-with-yongsu-ahn-and-alex-cabrera/'>fairness\n    and machine learning.\u003C/a>\n- date: 'July 23, 2019'\n  news: We will be presenting FairVis as a conference paper at VIS'19.\n- date: 'May 6, 2019'\n  news: >-\n    Our work on discovering intersectional bias was accepted to the \u003Ca\n    href='https://debug-ml-iclr2019.github.io/'>Debugging Machine Learning\n    Models workshop\u003C/a> at ICLR'19 in New Orleans.\n- date: 'April 10, 2019'\n  news: \"Named a \u003Ca href='https://www.nsfgrfp.org/'>NSF Graduate Research Fellow.\u003C/a>\"\n- date: 'April 3, 2019'\n  news: >-\n    Excited to be starting my PhD in Human-Computer Interaction at Carnegie\n    Mellon in Fall 2019!\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/zeno.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning'\nid: zeno\nteaser: zeno.png\nvenue: CHI'23\nvenuelong: >-\n  ACM Conference on Conference on Human Factors in Computing Systems\n  (CHI)\nyear: '2023'\nmonth: May\nlocation: Hamburg, Germany\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Erica Fu\n    website: https://ericafu.me/\n  - name: Donald Bertucci\n    website: https://www.donnybertucci.com/\n  - name: Kenneth Holstein\n    website: https://www.thecoalalab.com/kenholstein\n  - name: Ameet Talwalkar\n    website: https://www.cs.cmu.edu/~atalwalk/\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\n  - name: Adam Perer\n    website: 'http://perer.org'\ncode: https://github.com/zeno-ml/zeno\nweb: http://zenoml.com\npdf: https://dl.acm.org/doi/pdf/10.1145/3544548.3581268\ncitation: https://doi.org/10.1145/3544548.3581268\nbibtex: >-\n  @inproceedings{cabrera2023zeno,\n  author = {Cabrera, \\'{A}ngel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I. and Perer, Adam},\n  title = {Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning},\n  year = {2023},\n  isbn = {9781450394215},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3544548.3581268},\n  doi = {10.1145/3544548.3581268},\n  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},\n  articleno = {419},\n  numpages = {14},\n  keywords = {visualization, testing, machine learning, evaluation},\n  location = {Hamburg, Germany},\n  series = {CHI '23}\n  }\nabstract: >-\n  Machine learning models with high accuracy on test data can still produce systematic failures, such as harmful biases and safety issues, when deployed in the real world.\n  To detect and mitigate such failures, practitioners run behavioral evaluation of their models, checking model outputs for specific types of inputs.\n  Behavioral evaluation is important but challenging, requiring practitioners to discover real-world patterns and validate systematic failures. \n  We conducted 18 semi-structured interviews with ML practitioners to better understand the challenges of behavioral evaluation and found that it is a collaborative, use-case-first process that is not adequately supported by existing task- and domain-specific tools.\n  Using these findings, we designed Zeno, a general-purpose framework for visualizing and testing AI systems across diverse use cases.\n  In four case studies with participants using Zeno on real-world models, we found that practitioners were able to reproduce previous manual analyses and discover new systematic failures.\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/behavior.yml">{"status":200,"statusText":"","headers":{},"body":"title: Improving Human-AI Collaboration with Descriptions of AI Behavior\nabstract: >-\n  People work with AI systems to improve their decision making, but often under- or over-rely on AI predictions and perform worse than they would have unassisted. To help people appropriately rely on AI aids, we propose showing them behavior descriptions, details of how AI systems perform on subgroups of instances. We tested the efficacy of behavior descriptions through user studies with 225 participants in three distinct domains: fake review detection, satellite image classification, and bird classification. We found that behavior descriptions can increase human-AI accuracy through two mechanisms: helping people identify AI failures and increasing people's reliance on the AI when it is more accurate. These findings highlight the importance of people's mental models in human-AI collaboration and show that informing people of high-level AI behaviors can significantly improve AI-assisted decision making.\nid: behavior\nteaser: behavior.png\nvenue: CSCW'23\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2023'\nmonth: October\nlocation: Minneapolis\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3579612'\nurl: 'https://doi.org/10.1145/3579612'\ndoi: '10.1145/3579612'\ncitation: 'https://dl.acm.org/doi/10.1145/3579612'\nbibtex: >-\n  @article{cabrera2022behavior,\n  author = {Cabrera, \\'{A}ngel Alexander and Perer, Adam and Hong, Jason I.},\n  title = {Improving Human-AI Collaboration With Descriptions of AI Behavior},\n  year = {2023},\n  issue_date = {April 2023},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  volume = {7},\n  number = {CSCW1},\n  url = {https://doi.org/10.1145/3579612},\n  doi = {10.1145/3579612},\n  journal = {Proc. ACM Hum.-Comput. Interact.},\n  month = {apr},\n  articleno = {136},\n  numpages = {21},\n  }\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/aiffinity.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'What Did My AI Learn? How Data Scientists Make Sense of Model Behavior'\nid: aiffinity\nteaser: aiffinity.png\nvenue: TOCHI'22\nvenuelong: >-\n  ACM Transactions on Computer-Human Interaction (TOCHI)\nyear: '2023'\nmonth: February\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Marco Tulio Ribeiro\n    website: https://homes.cs.washington.edu/~marcotcr/\n  - name: Bongshin Lee\n    website: http://bongshiny.com/\n  - name: Rob DeLine\n    website: https://www.microsoft.com/en-us/research/people/rdeline/\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Steven M. Drucker\n    website: 'https://www.microsoft.com/en-us/research/people/sdrucker/'\nabstract: >-\n  Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them.\n  Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned.\n  We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior.\n  To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design AIFinnity, a system for analyzing image-and-text models. \n  Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using AIFinnity to pick an image captioning model.\n  We found that AIFinnity's sensemaking workflow reflected participants' mental processes and enabled them to discover and validate diverse AI behaviors.\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3542921'\ncitation: 'https://dl.acm.org/doi/10.1145/3542921'\nbibtex: >-\n  @article{Cabrera2023AIfinnity,\n    author = {Cabrera, \\'{A}ngel Alexander and Tulio Ribeiro, Marco and Lee, Bongshin and Deline, Robert and Perer, Adam and Drucker, Steven M.},\n    title = {What Did My AI Learn? How Data Scientists Make Sense of Model Behavior},\n    year = {2023},\n    issue_date = {February 2023},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    volume = {30},\n    number = {1},\n    issn = {1073-0516},\n    url = {https://doi.org/10.1145/3542921},\n    doi = {10.1145/3542921},\n    journal = {ACM Trans. Comput.-Hum. Interact.},\n    month = {mar},\n    articleno = {1},\n    numpages = {27},\n  }\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/symphony.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'Symphony: Composing Interactive Interfaces for Machine Learning'\nid: symphony\nteaser: symphony.png\nvenue: CHI'22\nvenuelong: >-\n  ACM Conference on Conference on Human Factors in Computing Systems\n  (CHI)\nyear: '2022'\nmonth: May\nlocation: New Orleans\nauthors:\n  - name: Ángel Alexander Cabrera*\n    website: 'https://cabreraalex.com'\n  - name: Alex Bäuerle*\n    website: https://a13x.io/\n  - name: Fred Hohman\n    website: https://fredhohman.com/\n  - name: Megan Maher\n  - name: David Koski\n  - name: Xavier Suau\n  - name: Titus Barik\n    website: https://www.barik.net/\n  - name: Dominik Moritz\n    website: https://www.domoritz.de/\nabstract: >-\n  Interfaces for machine learning (ML), information and visualizations about models or data, can help practitioners build robust and responsible ML systems.\n  Despite their benefits, recent studies of ML teams and our interviews with practitioners (n=9) showed that ML interfaces have limited adoption in practice.\n  While existing ML interfaces are effective for specific tasks, they are not designed to be reused, explored, and shared by multiple stakeholders in cross-functional teams.\n  To enable analysis and communication between different ML practitioners, we designed and implemented Symphony, a framework for composing interactive ML interfaces with task-specific, data-driven components that can be used across platforms such as computational notebooks and web dashboards.\n  We developed Symphony through participatory design sessions with 10 teams (n=31), and discuss our findings from deploying Symphony to 3 production ML projects at Apple.\n  Symphony helped ML practitioners discover previously unknown issues like data duplicates and blind spots in models while enabling them to share insights with other stakeholders.\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3491102.3502102'\nvideo: 'https://www.youtube.com/watch?v=0Q3wIh3AiPs'\nbibtex: >-\n  @inproceedings{symphony,\n  author = {B\\\"{a}uerle, Alex and Cabrera, \\'{A}ngel Alexander and Hohman, Fred and Maher, Megan and Koski, David and Suau, Xavier and Barik, Titus and Moritz, Dominik},\n  title = {Symphony: Composing Interactive Interfaces for Machine Learning},\n  year = {2022},\n  isbn = {9781450391573},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3491102.3502102},\n  doi = {10.1145/3491102.3502102},\n  booktitle = {CHI Conference on Human Factors in Computing Systems},\n  articleno = {210},\n  numpages = {14},\n  location = {New Orleans, LA, USA},\n  series = {CHI '22}\n  }\ncitation: 'https://dl.acm.org/doi/10.1145/3491102.3502102'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/covidcast.yml">{"status":200,"statusText":"","headers":{},"body":"title: An open repository of real-time COVID-19 indicators\ndesc: 'We created an interactive dashboard for tracking COVID-19 indicators. The\n  indicators are collected from various sources such as social media surveys\n  and testing labs, and can be used to predict or better understand factors in\n  the spread and severity of COVID-19.'\nid: covidcast\nteaser: covidcast.png\nvenue: PNAS'21\nvenuelong: Proceedings of the National Academy of Sciences (PNAS)\nyear: '2021'\nmonth: December\nauthors:\n  - name: Alex Reinhart\n  - name: Logan Brooks\n  - name: Maria Jahja\n  - name: Aaron Rumack\n  - name: Jingjing Tang\n  - name: '[et al, including Ángel Alexander Cabrera]'\nabstract: 'The COVID-19 pandemic presented enormous data challenges in the United\n  States. Policy makers, epidemiological modelers, and health researchers all\n  require up-to-date data on the pandemic and relevant public behavior,\n  ideally at fine spatial and temporal resolution. The COVIDcast API is our\n  attempt to fill this need: Operational since April 2020, it provides open\n  access to both traditional public health surveillance signals (cases,\n  deaths, and hospitalizations) and many auxiliary indicators of COVID-19\n  activity, such as signals extracted from deidentified medical claims data,\n  massive online surveys, cell phone mobility data, and internet search\n  trends. These are available at a fine geographic resolution (mostly at the\n  county level) and are updated daily. The COVIDcast API also tracks all\n  revisions to historical data, allowing modelers to account for the frequent\n  revisions and backfill that are common for many public health data sources.\n  All of the data are available in a common format through the API and\n  accompanying R and Python software packages. This paper describes the data\n  sources and signals, and provides examples demonstrating that the auxiliary\n  signals in the COVIDcast API present information relevant to tracking COVID\n  activity, augmenting traditional public health reporting and empowering\n  research and decision-making.'\npdf: 'https://www.pnas.org/content/pnas/118/51/e2111452118.full.pdf'\nbibtex: \"@article{Reinhart2021,doi = {10.1073/pnas.2111452118},url =\n  {https://doi.org/10.1073/pnas.2111452118},year = {2021},month =\n  dec,publisher = {Proceedings of the National Academy of Sciences},volume =\n  {118},number = {51},pages = {e2111452118},author = {Alex Reinhart and Logan\n  Brooks and Maria Jahja and Aaron Rumack and Jingjing Tang and Sumit Agrawal\n  and Wael Al Saeed and Taylor Arnold and Amartya Basu and Jacob Bien and\n  {'{A}}ngel A. Cabrera and Andrew Chin and Eu Jing Chua and Brian Clark and\n  Sarah Colquhoun and Nat DeFries and David C. Farrow and Jodi Forlizzi and\n  Jed Grabman and Samuel Gratzl and Alden Green and George Haff and Robin Han\n  and Kate Harwood and Addison J. Hu and Raphael Hyde and Sangwon Hyun and\n  Ananya Joshi and Jimi Kim and Andrew Kuznetsov and Wichada La Motte-Kerr and\n  Yeon Jin Lee and Kenneth Lee and Zachary C. Lipton and Michael X. Liu and\n  Lester Mackey and Kathryn Mazaitis and Daniel J. McDonald and Phillip\n  McGuinness and Balasubramanian Narasimhan and Michael P. O'Brien and Natalia\n  L. Oliveira and Pratik Patil and Adam Perer and Collin A. Politsch and\n  Samyak Rajanala and Dawn Rucker and Chris Scott and Nigam H. Shah and Vishnu\n  Shankar and James Sharpnack and Dmitry Shemetov and Noah Simon and Benjamin\n  Y. Smith and Vishakha Srivastava and Shuyi Tan and Robert Tibshirani and\n  Elena Tuzhilina and Ana Karina Van Nortwick and Val{'{e}}rie Ventura and\n  Larry Wasserman and Benjamin Weaver and Jeremy C. Weiss and Spencer Whitman\n  and Kristin Williams and Roni Rosenfeld and Ryan J. Tibshirani},title = {An\n  open repository of real-time {COVID}-19 indicators},journal = {Proceedings\n  of the National Academy of Sciences}}\"\ncitation: 'https://www.pnas.org/doi/10.1073/pnas.2111452118'\ncode: 'https://github.com/cmu-delphi/www-covidcast'\nweb: 'https://delphi.cmu.edu/covidcast/'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/deblinder.yml">{"status":200,"statusText":"","headers":{},"body":"title: Discovering and Validating AI Errors With Crowdsourced Failure Reports\ndesc: >-\n  We introduce failure reports, end-user descriptions of how an AI system\n  failed, and show how they can be used to detect systematic AI errors. We\n  also designed and implemented Deblinder, a visual analytics system data\n  scientists can use to explore and validate patterns from failure reports. In\n  a user study, we found that data scientists found consistent failures and\n  that collecting data from those failure areas significantly increased model\n  performance.\nid: deblinder\nteaser: deblinder.jpg\nvenue: CSCW'21\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2021'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Abraham Druck\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\n  - name: Adam Perer\n    website: 'http://perer.org'\nabstract: >-\n  AI systems can fail to learn important behaviors, leading to real-world\n  issues like safety concerns and biases. Unfortunately, discovering these\n  systematic failures often requires significant developer attention, from\n  hypothesizing potential edge cases to collecting evidence and validating\n  patterns. To scale and streamlinethis process, we introduce failure reports,\n  end-user descriptions of how or why a model failed, and show how developers\n  can use them to detect AI errors. We also design and implement Deblinder, a\n  visual analytics system for synthesizing failure reports that developers can\n  use to discover and validate systematic failures. In semi-structured\n  interviews and think-aloud studies with 10 AI practitioners, we explore the\n  affordances of the Deblinder system and the applicability of failure reports\n  in real-world settings. Lastly, we show how collecting additional data from\n  the groups identified by developers can improve model performance.\npdf: 'https://cabreraalex.com/deblinder.pdf'\nbibtex: >-\n  @article{cabrera2021deblinder,author = {Cabrera, '{A}ngel Alexander and\n  Druck, Abraham J. and Hong, Jason I. and Perer, Adam},title = {Discovering\n  and Validating AI Errors With Crowdsourced Failure Reports},year =\n  {2021},issue_date = {October 2021},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {5},number = {CSCW2},url =\n  {https://doi.org/10.1145/3479569},doi = {10.1145/3479569},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = oct,articleno = {425},numpages = {22}}\ncitation: 'https://dl.acm.org/doi/10.1145/3479569'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/expo.yml">{"status":200,"statusText":"","headers":{},"body":"title: Regularizing Black-box Models for Improved Interpretability\nid: expo\nteaser: expo.png\nvenue: NeurIPS'20\nvenuelong: Conference on Neural Information Processing Systems (NeurIPS)\nyear: '2020'\nmonth: December\nlocation: Vancouver\nauthors:\n  - name: Gregory Plumb\n    website: 'https://gdplumb.github.io/'\n  - name: Maruan Al-Shedivat\n    website: 'https://www.cs.cmu.edu/~mshediva/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org/'\n  - name: Eric Xing\n    website: 'http://www.cs.cmu.edu/~epxing/'\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @inproceedings{plumb2020expo,\n  author = {Plumb, Gregory and Al-Shedivat, Maruan and Cabrera, \\'{A}ngel Alexander and Perer, Adam and Xing, Eric and Talwalkar, Ameet},\n  title = {Regularizing Black-Box Models for Improved Interpretability},\n  year = {2020},\n  isbn = {9781713829546},\n  publisher = {Curran Associates Inc.},\n  address = {Red Hook, NY, USA},\n  booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},\n  articleno = {883},\n  numpages = {11},\n  location = {Vancouver, BC, Canada},\n  series = {NIPS'20}\n  }\ncitation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'\nabstract: >-\n  Most of the work on interpretable machine learning has focused on designing\n  either inherently interpretable models, which typically trade-off accuracy\n  for interpretability, or post-hoc explanation systems, which tend to lack\n  guarantees about the quality of their explanations. We explore a\n  hybridization of these approaches by directly regularizing a black-box model\n  for interpretability at training time - a method we call ExpO. We find that\n  post-hoc explanations of an ExpO-regularized model are consistently more\n  stable and of higher fidelity, which we show theoretically and support\n  empirically. Critically, we also find ExpO leads to explanations that are\n  more actionable, significantly more useful, and more intuitive as supported\n  by a user study.\npdf: 'https://dl.acm.org/doi/pdf/10.5555/3495724.3496607'\ncode: 'https://github.com/GDPlumb/ExpO'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/confusion.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  Designing Alternative Representations of Confusion Matrices to Support\n  Non-Expert Public Understanding of Algorithm Performance\ndesc: >-\n  We studied how non-experts use confusion matrices to understand machine\n  learning models. We then developed and tested multiple alternative\n  representations of model performance, finding that contextualized and\n  direcitonal representations are the most useful modifications for improving\n  understanding.\nid: confusion\nteaser: representations.png\nvenue: CSCW'20\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2020'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Hong Shen\n    website: 'https://www.andrew.cmu.edu/user//hongs/'\n  - name: Haojian Jin\n    website: 'http://shift-3.com/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Haiyi Zhu\n    website: 'https://haiyizhu.com/'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\nbibtex: >-\n  @article{shen2020confusion,author = {Shen, Hong and Jin, Haojian and\n  Cabrera, '{A}ngel Alexander and Perer, Adam and Zhu, Haiyi and Hong, Jason\n  I.},title = {Designing Alternative Representations of Confusion Matrices to\n  Support Non-Expert Public Understanding of Algorithm Performance},year =\n  {2020},issue_date = {October 2020},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {4},number = {CSCW2},url =\n  {https://doi.org/10.1145/3415224},doi = {10.1145/3415224},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = {oct},articleno = {153},numpages = {22}}\nabstract: >-\n  Ensuring effective public understanding of algorithmic decisions that are\n  powered by machine learning techniques has become an urgent task with the\n  increasing deployment of AI systems into our society. In this work, we\n  present a concrete step toward this goal by redesigning confusion matrices\n  for binary classification to support non-experts in understanding the\n  performance of machine learning models. Through interviews (n=7) and a\n  survey (n=102), we mapped out two major sets of challenges lay people have\n  in understanding standard confusion matrices: the general terminologies and\n  the matrix design. We further identified three sub-challenges regarding the\n  matrix design, namely, confusion about the direction of reading the data,\n  layered relations and quantities involved. We then conducted an online\n  experiment with 483 participants to evaluate how effective a series of\n  alternative representations target each of those challenges in the context\n  of an algorithm for making recidivism predictions. We developed three levels\n  of questions to evaluate users' objective understanding. We assessed the\n  effectiveness of our alternatives for accuracy in answering those questions,\n  completion time, and subjective understanding. Our results suggest that (1)\n  only by contextualizing terminologies can we significantly improve users'\n  understanding and (2) flow charts, which help point out the direction of\n  reading the data, were most useful in improving objective understanding. Our\n  findings set the stage for developing more intuitive and generally\n  understandable representations of the performance of machine learning\n  models.\npdf: 'https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf'\ncitation: 'https://dl.acm.org/doi/10.1145/3415224'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/fairvis.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  FairVis: Visual Analytics for Discovering Intersectional Bias in Machine\n  Learning\ndesc: >-\n  FairVis is a visual analytics system that enables data scientists to find\n  potential biases in their machine learning models. It allows users to split\n  their data into subgroups of different features to see how vulnerable groups\n  are performing for various fairness metrics. Additionally, it suggests\n  groups that may be underperforming and can find similar groups.\nid: fairvis\nteaser: fairvis.png\nvenue: VIS'19\nvenuelong: IEEE Conference on Visual Analytics Science and Technology (VAST)\nyear: '2019'\nmonth: October\nlocation: 'Vancouver, Canada'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Will Epperson\n    website: 'http://willepperson.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Minsuk Kahng\n    website: 'https://minsuk.com'\n  - name: Jamie Morgenstern\n    website: 'http://jamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @INPROCEEDINGS{cabrera2019fairvis, author={Á. A. {Cabrera} and W. {Epperson}\n  and F. {Hohman} and M. {Kahng} and J. {Morgenstern} and D. H. {Chau}},\n  booktitle={2019 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)}, title={FAIRVIS: Visual Analytics for Discovering Intersectional\n  Bias in Machine Learning}, year={2019}, volume={}, number={},\n  pages={46-56},doi={10.1109/VAST47406.2019.8986948}}\nabstract: >-\n  The growing capability and accessibility of machine learning has led to its\n  application to many real-world domains and data about people. Despite the\n  benefits algorithmic systems may bring, models can reflect, inject, or\n  exacerbate implicit and explicit societal biases into their outputs,\n  disadvantaging certain demographic subgroups. Discovering which biases a\n  machine learning model has introduced is a great challenge, due to the\n  numerous definitions of fairness and the large number of potentially\n  impacted subgroups. We present FairVis, a mixed-initiative visual analytics\n  system that integrates a novel subgroup discovery technique for users to\n  audit the fairness of machine learning models. Through FairVis, users can\n  apply domain knowledge to generate and investigate known subgroups, and\n  explore suggested and similar subgroups. FairVis' coordinated views enable\n  users to explore a high-level overview of subgroup performance and\n  subsequently drill down into detailed investigation of specific subgroups.\n  We show how FairVis helps to discover biases in two real datasets used in\n  predicting income and recidivism. As a visual analytics system devoted to\n  discovering bias in machine learning, FairVis demonstrates how interactive\n  visualization may help data scientists and the general public understand and\n  create more equitable algorithmic systems.\nweb: 'https://poloclub.github.io/FairVis/'\ncode: 'https://github.com/poloclub/FairVis'\nblog: >-\n  https://medium.com/@cabreraalex/fairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f\npdf: 'https://arxiv.org/abs/1904.05419'\nvideo: 'https://vimeo.com/showcase/6524122/video/368702211'\ncitation: 'https://ieeexplore.ieee.org/document/8986948'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/spotcheck.yml">{"status":200,"statusText":"","headers":{},"body":"title: Evaluating Systemic Error Detection Methods using Synthetic Images\nid: spotcheck\nteaser: spotcheck.png\nvenue: \"Workshop, ICML'22\"\nvenuelong: ICML - Workshop on Spurious Correlations, Invariance and Stability\nyear: '2022'\nmonth: July\nlocation: Baltimore, MD\nauthors:\n  - name: Gregory Plumb\n    website: 'https://gdplumb.github.io/'\n  - name: Nari Johnson\n    website: 'https://njohnson99.github.io/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Marco Tulio Ribeiro\n    website: https://homes.cs.washington.edu/~marcotcr/\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @inproceedings{plumb2020expo,\n  author = {Plumb, Gregory and Johnson, Nari and Cabrera, \\'{A}ngel Alexander and Ribeiro, Marco Tulio and Talwalkar, Ameet},\n  title = {Evaluating Systemic Error Detection Methods using Synthetic Images},\n  year = {2022},\n  booktitle = {Workshop on Spurious Correlations, Invariance and Stability at International Conference on Machine Learning},\n  }\n# citation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'\nabstract: >-\n  We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.\npdf: 'https://arxiv.org/pdf/2207.04104.pdf'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/publics.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  \"Public(s)-in-the-Loop\": Facilitating Deliberation of Algorithmic Decisions\n  in Contentious Public Policy Domains\ndesc: >-\n  We introduce a framework for thinking about how to better involve human\n  influence in algorithmic decision-making of contentious public policy\n  issues.\nid: publics\nteaser: publics-in-loop.png\nvenue: \"Workshop, CHI'20\"\nvenuelong: CHI - Fair & Responsible AI Workshop\nyear: '2020'\nmonth: May\nlocation: 'Hawaii, USA'\nauthors:\n  - name: Hong Shen\n    website: 'https://www.andrew.cmu.edu/user//hongs/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\nbibtex: >-\n  @article{hong2020publics, title={\"Public(s)-in-the-Loop\": Facilitating\n  Deliberation of Algorithmic Decisions in Contentious Public Policy Domains},\n  author={Shen, Hong and Cabrera, Ángel Alexander and Perer, Adam and Hong,\n  Jason}, journal={Fair & Responsible AI Workshop at CHI}, year={2020}}\nabstract: >-\n  This position paper offers a framework to think about how to better involve\n  human influence in algorithmic decision-making of contentious public policy\n  issues. Drawing from insights in communication literature, we introduce a\n  ``public(s)-in-the-loop'' approach and enumerates three features that are\n  central to this approach: publics as plural political entities, collective\n  decision-making through deliberation, and the construction of publics. It\n  explores how these features might advance our understanding of stakeholder\n  participation in AI design in contentious public policy domains such as\n  recidivism prediction. Finally, it sketches out part of a research agenda\n  for the HCI community to support this work.\npdf: 'https://www.andrew.cmu.edu/user/hongs/files/20_chi_workshop_publics.pdf'\nworkshop: 'http://fair-ai.owlstown.com/'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/subgroup-gen.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  Discovery of Intersectional Bias in Machine Learning Using Automatic\n  Subgroup Generation\ndesc: >-\n  We introduce a method for automatically generating subgroups of instances\n  that a model may be biased against. The instances are first clustered and\n  then described by their dominating features. By ranking and sorting the\n  groups by their performance metrics (F1, accuracy, etc. ) users can spot\n  groups that are underperforming.\nid: subgroup-gen\nteaser: iclr.png\nvenue: \"Workshop, ICLR'19\"\nvenuelong: ICLR - Debugging Machine Learning Models Workshop (Debug ML)\nyear: '2019'\nmonth: May\nlocation: 'New Orleans, Louisiana, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Minsuk Kahng\n    website: 'https://minsuk.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Jamie Morgenstern\n    website: 'http://jamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @article{cabrera2019discovery, title={Discovery of Intersectional Bias in\n  Machine Learning Using Automatic Subgroup Generation}, author={Cabrera,\n  Ángel Alexander and Kahng, Minsuk and Hohman, Fred and Morgenstern, Jamie\n  and Chau, Duen Horng}, journal={Debugging Machine Learning Models Workshop\n  (Debug ML) at ICLR}, year={2019}}\nabstract: >-\n  As machine learning is applied to data about people, it is crucial to\n  understand how learned models treat different demographic groups. Many\n  factors, including what training data and class of models are used, can\n  encode biased behavior into learned outcomes. These biases are often small\n  when considering a single feature (e.g., sex or race) in isolation, but\n  appear more blatantly at the intersection of multiple features. We present\n  our ongoing work of designing automatic techniques and interactive tools to\n  help users discover subgroups of data instances on which a model\n  underperforms. Using a bottom-up clustering technique for subgroup\n  generation, users can quickly find areas of a dataset in which their models\n  are encoding bias. Our work presents some of the first user-focused,\n  interactive methods for discovering bias in machine learning models.\npdf: 'https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_3.pdf'\nworkshop: 'https://debug-ml-iclr2019.github.io/'\n"}</script>
	<script type="application/json" data-sveltekit-fetched data-url="/pubs/interactive-classification.yml">{"status":200,"statusText":"","headers":{},"body":"title: Interactive Classification for Deep Learning Interpretation\ndesc: >-\n  We developed an interactive system that allows users to modify images to\n  explore the weaknesses and strenghts of image classification models. Users\n  can 'inpaint' or remove parts of an image and see how it impacts their\n  classification.\nid: interactive-classification\nteaser: interactive.png\nvenue: \"Demo, CVPR'18\"\nvenuelong: CVPR - Demo\nyear: '2018'\nmonth: June\nlocation: 'Salt Lake City, Utah, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Jason Lin\n    website: 'http://jlin.xyz'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @article{cabrera2018interactive, title={Interactive Classification for Deep\n  Learning Interpretation}, author={Cabrera, Ángel Alexander and Hohman, Fred\n  and Lin, Jason and Chau, Duen Horng}, journal={Demo, IEEE Conference on\n  Computer Vision and Pattern Recognition (CVPR)}, year={2018},\n  organization={IEEE}}\nabstract: >-\n  We present an interactive system enabling users to manipulate images to\n  explore the robustness and sensitivity of deep learning image classifiers.\n  Using modern web technologies to run in-browser inference, users can remove\n  image features using inpainting algorithms to obtain new classifications in\n  real time. This system allows users to compare and contrast what image\n  regions humans and machine learning models use for classification.\npdf: 'https://arxiv.org/abs/1806.05660'\nvideo: 'https://www.youtube.com/watch?v=llub5GcOF6w'\nweb: 'https://cabreraalex.github.io/interactive-classification'\ncode: 'https://github.com/poloclub/interactive-classification'\n"}</script></div>
		<!-- Cronitor RUM -->
		<script async src="https://rum.cronitor.io/script.js"></script>
		<script>
			window.cronitor =
				window.cronitor ||
				function () {
					(window.cronitor.q = window.cronitor.q || []).push(arguments);
				};
			cronitor('config', { clientKey: 'fc3bd3b150ba04ebd0e73c00be9eff39' });
		</script>
	</body>
</html>
