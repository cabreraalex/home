<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link
			rel="stylesheet"
			href="https://unpkg.com/purecss@1.0.1/build/pure-min.css"
			integrity="sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47"
			crossorigin="anonymous"
		/>
		<link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css" />
		<link
			rel="stylesheet"
			href="https://use.fontawesome.com/releases/v5.0.12/css/all.css"
			integrity="sha384-G0fIWCsCzJIMAVNQPfjH08cyYaUtMwjJwqiRKxxE/rx96Uroj1BtIQ6MLJuheaO9"
			crossorigin="anonymous"
		/>
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link
			href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link rel="stylesheet" href="./global.css" />
		<link rel="icon" href="./favicon.png" />
		
		<link href="./_app/immutable/assets/2.C9vW1Ytk.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Social.DLbjjjbe.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Footer.Dem8Qb1g.css" rel="stylesheet">
		<link href="./_app/immutable/assets/3.BswMrv3h.css" rel="stylesheet">
		<link href="./_app/immutable/assets/Links.BlD_4Dup.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.DNKtDXHz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.Dm9HFDyJ.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.DUa3pFyD.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.CRPD1fuC.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.x8VGGEhm.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.Bv_hjRoc.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.DGqvPJOK.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Social.12N3jlUR.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Footer.B8LiSrLh.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/3.BV4Y63cD.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/js-yaml.mbYHt68G.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Intro.BrZJ1eBO.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/each.D6YF6ztN.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Links.DGNkMOdY.js">
	</head>
	<body>
		<div>  <div class="pure-g" id="main-container"><div id="sidebar" class="pure-u-1 pure-u-md-1-4"><div id="padded-sidebar" class="svelte-ogw1pb"><a href="/" data-svelte-h="svelte-o0rmv5"><img width="180px" src="images/profile.png" alt="profile" class="svelte-ogw1pb"></a> <h1 id="name" class="svelte-ogw1pb" data-svelte-h="svelte-j0adee"><span class="color svelte-ogw1pb">Ángel </span> <br> <span class="color red svelte-ogw1pb">Alex</span> <span class="color svelte-ogw1pb">ander</span> <br> <span class="color red svelte-ogw1pb">Cabrera</span></h1> <div id="social"> <a href="mailto:cabrera@cmu.edu" data-svelte-h="svelte-554807"><h3 class="svelte-k1wkez"><i class="fas fa-envelope"></i>   cabrera@cmu.edu</h3></a> <a href="https://twitter.com/a_a_cabrera" data-svelte-h="svelte-14y0t7u"><h3 class="svelte-k1wkez"><i class="fab fa-twitter social-icon"></i>   @a_a_cabrera</h3></a> <a href="https://cabreraalex.medium.com/" data-svelte-h="svelte-egwpa3"><h3 class="svelte-k1wkez"><i class="fab fa-medium-m"></i>   Blog</h3></a> <a href="https://scholar.google.com/citations?user=r89SDm0AAAAJ&amp;hl=en" data-svelte-h="svelte-106itr1"><h3 class="svelte-k1wkez"><i class="fas fa-graduation-cap"></i>  Google Scholar</h3></a> <a href="https://github.com/cabreraalex" data-svelte-h="svelte-14vg54q"><h3 class="svelte-k1wkez"><i class="fab fa-github"></i>   GitHub</h3></a> </div> <a href="/cv" data-svelte-h="svelte-1lb5yyr"><button class="cv">CV (web)</button></a> <a href="/cv.pdf" rel="external" data-svelte-h="svelte-189mw04"><button class="cv">CV (pdf)</button></a></div> </div> <div id="content" class="pure-u-1 pure-u-md-3-4"><div id="padded-content"><div id="intro"><h2 class="header svelte-1on3tlv" style="font-size: 28px; font-weight: 500" data-svelte-h="svelte-1cvj4dc">Hi! You can call me <span class="name">Alex</span></h2> <p data-svelte-h="svelte-1sotbsa">I am currently a founding engineer at <a href="https://axi.om">Axiom Bio</a>, applying ML to
	predict molecular toxicity.
	<br> <br>

	Previously, I got my PhD in the
	<a href="https://hcii.cmu.edu/">Human-Computer Interaction Institute (HCII)</a>
	at Carnegie Mellon University, advised by
	<a href="http://perer.org">Adam Perer</a>
	and
	<a href="http://www.cs.cmu.edu/~jasonh/">Jason Hong.</a>
	I worked on human-centered AI, specifically using techniques from HCI and visualization to help people
	better understand and improve their AI systems. I was supported by an
	<a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a>
	and have spent time at Apple AI/ML, Microsoft Research, &amp; Google.</p></div> <div id="news" class="sect"><div class="inline svelte-1on3tlv" data-svelte-h="svelte-kru3k7"><h2 class="header svelte-1on3tlv">News</h2> <p><a class="right-all" href="/news">see all</a></p></div> <hr> <div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">April 26, 2024</p> <p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->Started as founding engineer at <a href="https://axi.om">Axiom Bio</a>.<!-- HTML_TAG_END --></p> </div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">March 21, 2024</p> <p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->I successfully defended my thesis 🎉.<!-- HTML_TAG_END --></p> </div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">March 1, 2024</p> <p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->We launched <a href="https://endoftext.app">&lt;|endoftext|&gt;</a>, an AI-powered prompt editor.<!-- HTML_TAG_END --></p> </div></div> <div id="pubs" class="sect"><div class="inline svelte-1on3tlv" data-svelte-h="svelte-bstwwd"><h2 class="header svelte-1on3tlv">Publications</h2></div> <hr> <div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/sot"><div style="background-image: url(images/sot.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>SOT, 2025</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/sot"><h4 class="paper-title">Accurate and interpretable in silico clinical risk assessment for drug-induced liver injury (DILI) from molecular structure</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='javascript:void(0);'>Katherine Titterton</a>, <a class=' author' href='javascript:void(0);'>Daniil Boiko</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='javascript:void(0);'>Alex Bäuerle</a>, <a class=' author' href='javascript:void(0);'>Akshit Tyagi</a>, <a class=' author' href='javascript:void(0);'>Shahin Saneinejad</a>, <a class=' author' href='javascript:void(0);'>Alex Beatson</a>, <a class=' author' href='javascript:void(0);'>Brandon White</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="/axiom-sot.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>        <a href="/paper/sot"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/cytotox"><div style="background-image: url(images/cytotox.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>Preprint, 2025</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/cytotox"><h4 class="paper-title">Cell Painting for cytotoxicity and mode-of-action analysis in primary human hepatocytes</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='javascript:void(0);'>Jessica Ewald</a>, <a class=' author' href='javascript:void(0);'>Katherine Titterton</a>, <a class=' author' href='javascript:void(0);'>Alex Bäuerle</a>, <a class=' author' href='javascript:void(0);'>Alex Beatson</a>, <a class=' author' href='javascript:void(0);'>Daniil Boiko</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='javascript:void(0);'>Jaime Cheah</a>, <a class=' author' href='javascript:void(0);'>Beth Cimini</a>, <a class=' author' href='javascript:void(0);'>Bram Gorissen</a>, <a class=' author' href='javascript:void(0);'>Thouis Jones</a>, <a class=' author' href='javascript:void(0);'>Konrad Karczewski</a>, <a class=' author' href='javascript:void(0);'>David Rouquié</a>, <a class=' author' href='javascript:void(0);'>Srijit Seal</a>, <a class=' author' href='javascript:void(0);'>Erin Weisbart</a>, <a class=' author' href='javascript:void(0);'>Brandon White</a>, <a class=' author' href='javascript:void(0);'>Anne Carpenter</a>, <a class=' author' href='javascript:void(0);'>Shantanu Singh</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://www.biorxiv.org/content/10.1101/2025.01.22.634152v1.full.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>        <a href="/paper/cytotox"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/slicing"><div style="background-image: url(images/slicing.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>HCOMP'23</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/slicing"><h4 class="paper-title">Where Does My Model Underperform? A Human Evaluation of Slice Discovery Algorithms</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://njohnson99.github.io/'>Nari Johnson</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://arxiv.org/pdf/2306.08167.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>        <a href="/paper/slicing"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a> <div class="award-container svelte-14wssdf"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="15px"><title>trophy</title><path d="M18 2C17.1 2 16 3 16 4H8C8 3 6.9 2 6 2H2V11C2 12 3 13 4 13H6.2C6.6 15 7.9 16.7 11 17V19.08C8 19.54 8 22 8 22H16C16 22 16 19.54 13 19.08V17C16.1 16.7 17.4 15 17.8 13H20C21 13 22 12 22 11V2H18M6 11H4V4H6V11M20 11H18V4H20V11Z"></path></svg> <p class="award svelte-14wssdf">Best Paper</p></div> </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/blindspots"><div style="background-image: url(images/spotcheck.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>TMLR</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/blindspots"><h4 class="paper-title">Towards a More Rigorous Science of Blindspot Discovery in Image Classification Models</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb*</a>, <a class=' author' href='https://njohnson99.github.io/'>Nari Johnson*</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://openreview.net/pdf?id=MaDvbLaBiF" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>      <a href="https://github.com/njohnson99/spotcheck"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/blindspots"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/zeno"><div style="background-image: url(images/zeno.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>CHI'23</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/zeno"><h4 class="paper-title">Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://ericafu.me/'>Erica Fu</a>, <a class=' author' href='https://www.donnybertucci.com/'>Donald Bertucci</a>, <a class=' author' href='https://www.thecoalalab.com/kenholstein'>Kenneth Holstein</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a>, <a class=' author' href='http://perer.org'>Adam Perer</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3581268" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://doi.org/10.1145/3544548.3581268"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a> <a href="http://zenoml.com"><button class="entry-link" data-svelte-h="svelte-1ein5qx"><i class="fas fa-globe"></i> <p>Website</p></button></a>    <a href="https://github.com/zeno-ml/zeno"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/zeno"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/behavior"><div style="background-image: url(images/behavior.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>CSCW'23</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/behavior"><h4 class="paper-title">Improving Human-AI Collaboration with Descriptions of AI Behavior</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3579612" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.1145/3579612"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>       <a href="/paper/behavior"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/aiffinity"><div style="background-image: url(images/aiffinity.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>TOCHI'22</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/aiffinity"><h4 class="paper-title">What Did My AI Learn? How Data Scientists Make Sense of Model Behavior</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://homes.cs.washington.edu/~marcotcr/'>Marco Tulio Ribeiro</a>, <a class=' author' href='http://bongshiny.com/'>Bongshin Lee</a>, <a class=' author' href='https://www.microsoft.com/en-us/research/people/rdeline/'>Rob DeLine</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='https://www.microsoft.com/en-us/research/people/sdrucker/'>Steven M. Drucker</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3542921" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.1145/3542921"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>       <a href="/paper/aiffinity"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/symphony"><div style="background-image: url(images/symphony.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>CHI'22</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/symphony"><h4 class="paper-title">Symphony: Composing Interactive Interfaces for Machine Learning</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera*</a>, <a class=' author' href='https://a13x.io/'>Alex Bäuerle*</a>, <a class=' author' href='https://fredhohman.com/'>Fred Hohman</a>, <a class=' author' href='javascript:void(0);'>Megan Maher</a>, <a class=' author' href='javascript:void(0);'>David Koski</a>, <a class=' author' href='javascript:void(0);'>Xavier Suau</a>, <a class=' author' href='https://www.barik.net/'>Titus Barik</a>, <a class=' author' href='https://www.domoritz.de/'>Dominik Moritz</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.1145/3491102.3502102" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.1145/3491102.3502102"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>    <a href="https://www.youtube.com/watch?v=0Q3wIh3AiPs"><button class="entry-link" data-svelte-h="svelte-19iw23a"><i class="fab fa-youtube"></i> <p>Video</p></button></a>   <a href="/paper/symphony"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/covidcast"><div style="background-image: url(images/covidcast.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>PNAS'21</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/covidcast"><h4 class="paper-title">An open repository of real-time COVID-19 indicators</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='javascript:void(0);'>Alex Reinhart</a>, <a class=' author' href='javascript:void(0);'>Logan Brooks</a>, <a class=' author' href='javascript:void(0);'>Maria Jahja</a>, <a class=' author' href='javascript:void(0);'>Aaron Rumack</a>, <a class=' author' href='javascript:void(0);'>Jingjing Tang</a>, <a class='me author' href='javascript:void(0);'>[et al, including Ángel Alexander Cabrera]</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://www.pnas.org/content/pnas/118/51/e2111452118.full.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://www.pnas.org/doi/10.1073/pnas.2111452118"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a> <a href="https://delphi.cmu.edu/covidcast/"><button class="entry-link" data-svelte-h="svelte-1ein5qx"><i class="fas fa-globe"></i> <p>Website</p></button></a>    <a href="https://github.com/cmu-delphi/www-covidcast"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/covidcast"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/deblinder"><div style="background-image: url(images/deblinder.jpg)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>CSCW'21</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/deblinder"><h4 class="paper-title">Discovering and Validating AI Errors With Crowdsourced Failure Reports</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='javascript:void(0);'>Abraham Druck</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a>, <a class=' author' href='http://perer.org'>Adam Perer</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://cabreraalex.com/deblinder.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.1145/3479569"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>       <a href="/paper/deblinder"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/expo"><div style="background-image: url(images/expo.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>NeurIPS'20</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/expo"><h4 class="paper-title">Regularizing Black-box Models for Improved Interpretability</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://www.cs.cmu.edu/~mshediva/'>Maruan Al-Shedivat</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org/'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~epxing/'>Eric Xing</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://dl.acm.org/doi/pdf/10.5555/3495724.3496607" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.5555/3495724.3496607"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>     <a href="https://github.com/GDPlumb/ExpO"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/expo"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/confusion"><div style="background-image: url(images/representations.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>CSCW'20</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/confusion"><h4 class="paper-title">Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class=' author' href='http://shift-3.com/'>Haojian Jin</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='https://haiyizhu.com/'>Haiyi Zhu</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://dl.acm.org/doi/10.1145/3415224"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a>       <a href="/paper/confusion"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/fairvis"><div style="background-image: url(images/fairvis.png)" class="thumb" alt="teaser"></div></a> <div class="image-caption svelte-1on3tlv"><p>VIS'19</p> </div></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/fairvis"><h4 class="paper-title">FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning</h4></a> <p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://willepperson.com'>Will Epperson</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://arxiv.org/abs/1904.05419" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a> <a href="https://ieeexplore.ieee.org/document/8986948"><button class="entry-link" data-svelte-h="svelte-q1rqvg"><i class="fas fa-book"></i> <p>BibTex</p></button></a> <a href="https://poloclub.github.io/FairVis/"><button class="entry-link" data-svelte-h="svelte-1ein5qx"><i class="fas fa-globe"></i> <p>Website</p></button></a> <a href="https://medium.com/@cabreraalex/fairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f"><button class="entry-link" data-svelte-h="svelte-3v8cqh"><i class="fab fa-medium"></i> <p>Blog</p></button></a>  <a href="https://vimeo.com/showcase/6524122/video/368702211"><button class="entry-link" data-svelte-h="svelte-19iw23a"><i class="fab fa-youtube"></i> <p>Video</p></button></a> <a href="https://github.com/poloclub/FairVis"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/fairvis"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div></div> <div id="pubs" class="sect"><div class="inline svelte-1on3tlv" data-svelte-h="svelte-62lxqc"><h2 class="header svelte-1on3tlv">Workshops, Demos, Posters, and Preprints</h2></div> <hr> <div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/gemini"><div style="background-image: url(images/gemini.png)" class="thumb" alt="teaser"></div></a> <p class="venue">Preprint, 2023</p></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/gemini"><h4 class="paper-title">An In-depth Look at Gemini's Language Abilities</h4></a> <p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://snat1505027.github.io/'>Syeda Nahida Akter</a>, <a class=' author' href='https://yuzc19.github.io/'>Zichun Yu</a>, <a class=' author' href='https://www.lti.cs.cmu.edu/people/222228510/aashiq-muhamed'>Aashiq Muhamed</a>, <a class=' author' href='https://www.lti.cs.cmu.edu/people/222228510/aashiq-muhamed'>Tianyue Ou</a>, <a class=' author' href='https://a13x.io'>Alex Bäuerle</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://github.com/BerriAI/litellm'>Krish Dholakia</a>, <a class=' author' href='https://www.cs.cmu.edu/~cx/'>Chenyan Xiong</a>, <a class=' author' href='https://photron.com'>Graham Neubig</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://arxiv.org/pdf/2312.11444.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>      <a href="https://github.com/neulab/gemini-benchmark"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/gemini"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/spotcheck"><div style="background-image: url(images/spotcheck.png)" class="thumb" alt="teaser"></div></a> <p class="venue">Workshop, ICML'22</p></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/spotcheck"><h4 class="paper-title">Evaluating Systemic Error Detection Methods using Synthetic Images</h4></a> <p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://njohnson99.github.io/'>Nari Johnson</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://homes.cs.washington.edu/~marcotcr/'>Marco Tulio Ribeiro</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://arxiv.org/pdf/2207.04104.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>        <a href="/paper/spotcheck"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/publics"><div style="background-image: url(images/publics-in-loop.png)" class="thumb" alt="teaser"></div></a> <p class="venue">Workshop, CHI'20</p></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/publics"><h4 class="paper-title">"Public(s)-in-the-Loop": Facilitating Deliberation of Algorithmic Decisions in Contentious Public Policy Domains</h4></a> <p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason I. Hong</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://www.andrew.cmu.edu/user/hongs/files/20_chi_workshop_publics.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>    <a href="http://fair-ai.owlstown.com/"><button class="entry-link" data-svelte-h="svelte-i4pek3"><i class="fas fa-globe"></i> <p>Workshop</p></button></a>    <a href="/paper/publics"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/subgroup-gen"><div style="background-image: url(images/iclr.png)" class="thumb" alt="teaser"></div></a> <p class="venue">Workshop, ICLR'19</p></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/subgroup-gen"><h4 class="paper-title">Discovery of Intersectional Bias in Machine Learning Using Automatic Subgroup Generation</h4></a> <p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_3.pdf" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>    <a href="https://debug-ml-iclr2019.github.io/"><button class="entry-link" data-svelte-h="svelte-i4pek3"><i class="fas fa-globe"></i> <p>Workshop</p></button></a>    <a href="/paper/subgroup-gen"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-4 svelte-1on3tlv"><a href="/paper/interactive-classification"><div style="background-image: url(images/interactive.png)" class="thumb" alt="teaser"></div></a> <p class="venue">Demo, CVPR'18</p></div> <div class="pure-u-1 pure-u-md-3-4"><div class="padded"><a href="/paper/interactive-classification"><h4 class="paper-title">Interactive Classification for Deep Learning Interpretation</h4></a> <p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jlin.xyz'>Jason Lin</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --> </p></div> <div class="buttons"><a href="https://arxiv.org/abs/1806.05660" rel="external"><button class="entry-link" data-svelte-h="svelte-kcqs98"><i class="fas fa-file-pdf"></i> <p>PDF</p></button></a>  <a href="https://cabreraalex.github.io/interactive-classification"><button class="entry-link" data-svelte-h="svelte-1ein5qx"><i class="fas fa-globe"></i> <p>Website</p></button></a>   <a href="https://www.youtube.com/watch?v=llub5GcOF6w"><button class="entry-link" data-svelte-h="svelte-19iw23a"><i class="fab fa-youtube"></i> <p>Video</p></button></a> <a href="https://github.com/poloclub/interactive-classification"><button class="entry-link" data-svelte-h="svelte-18x59fe"><i class="fab fa-github"></i> <p>Code</p></button></a>  <a href="/paper/interactive-classification"><button class="entry-link" data-svelte-h="svelte-ll0vtz"><i class="fas fa-info-circle"></i> <p>Details</p></button></a>  </div></div> </div></div> </div> <div class="footer svelte-1ynsxf6" data-svelte-h="svelte-p4b56a"><p id="copyright">© 2022 Ángel Alexander Cabrera - Made with
		<a href="https://svelte.dev">SvelteKit</a></p> </div></div></div> 
			<script type="application/json" data-sveltekit-fetched data-url="/news.yml">{"status":200,"statusText":"","headers":{},"body":"- date: 'April 26, 2024'\n  news: Started as founding engineer at \u003Ca href=\"https://axi.om\">Axiom Bio\u003C/a>.\n- date: 'March 21, 2024'\n  news: I successfully defended my thesis 🎉.\n- date: 'March 1, 2024'\n  news: We launched \u003Ca href=\"https://endoftext.app\">&lt;|endoftext|&gt;\u003C/a>, an AI-powered prompt editor.\n- date: 'January 10, 2024'\n  news: Our \u003Ca href=\"https://arxiv.org/pdf/2312.11444.pdf\">evals of Google's Gemini models\u003C/a> was featured by \u003Ca href=\"https://techcrunch.com/2024/01/07/what-is-google-gemini-ai/\">TechCrunch\u003C/a> & \u003Ca href=\"https://venturebeat.com/ai/google-gemini-is-not-even-as-good-as-gpt-3-5-turbo-researchers-find/\">VentureBeat\u003C/a>.\n- date: 'October 15, 2023'\n  news: We released \u003Ca href=\"https://hub.zenoml.com\">💠 Zeno Hub\u003C/a>, a full platform for AI evaluation and reporting.\n- date: 'August 10, 2023'\n  news: Apple open-sourced \u003Ca href=\"https://github.com/apple/ml-symphony\">Symphony 🎷\u003C/a>, our platform for modular ML interfaces.\n- date: 'March 6, 2023'\n  news: Zeno was selected for the \u003Ca href =\"https://foundation.mozilla.org/en/blog/auditing-ai-announcing-the-2023-mozilla-technology-fund-cohort/\">Mozilla Technology Fund on tools for auditing AI systems\u003C/a>.\n- date: 'February 1, 2023'\n  news: We announced \u003Ca href=\"https://zenoml.com\">&#128160; Zeno\u003C/a>, a general-purpose AI evaluation platform.\n- date: 'May 1, 2022'\n  news: Presenting \u003Ca href='https://dl.acm.org/doi/10.1145/3491102.3502102'>Symphony\u003C/a> at CHI'22 in New Orleans &#127927;\n- date: 'May 17, 2021'\n  news: First week at &#127822;!\n- date: 'May 18, 2020'\n  news: >-\n    Excited to spend the summer doing a ~virtual~ internship at Microsoft\n    Research with \u003Ca\n    href='https://www.microsoft.com/en-us/research/people/sdrucker/'>Steven\n    Drucker\u003C/a> at the \u003Ca\n    href='https://www.microsoft.com/en-us/research/group/vida/'>VIDA group.\u003C/a>\n- date: 'April 23, 2020'\n  news: >-\n    Our system for visualizing indicators of COVID symptoms \u003Ca\n    href='https://covidcast.cmu.edu/'>is live!\u003C/a>\n- date: 'March 5, 2020'\n  news: >-\n    Thanks to the Data Stories podcast for having Yongsu Ahn and me on their\n    show to talk about \u003Ca\n    href='https://datastori.es/156-fairness-in-machine-learning-with-yongsu-ahn-and-alex-cabrera/'>fairness\n    and machine learning.\u003C/a>\n- date: 'July 23, 2019'\n  news: We will be presenting FairVis as a conference paper at VIS'19.\n- date: 'May 6, 2019'\n  news: >-\n    Our work on discovering intersectional bias was accepted to the \u003Ca\n    href='https://debug-ml-iclr2019.github.io/'>Debugging Machine Learning\n    Models workshop\u003C/a> at ICLR'19 in New Orleans.\n- date: 'April 10, 2019'\n  news: \"Named a \u003Ca href='https://www.nsfgrfp.org/'>NSF Graduate Research Fellow.\u003C/a>\"\n- date: 'April 3, 2019'\n  news: >-\n    Excited to be starting my PhD in Human-Computer Interaction at Carnegie\n    Mellon in Fall 2019!\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/sot.yml">{"status":200,"statusText":"","headers":{},"body":"title: Accurate and interpretable in silico clinical risk assessment for drug-induced liver injury (DILI) from molecular structure\nabstract: >-\n  Drug-induced liver injury (DILI) is a leading cause of clinical trial failure and drug withdrawal, but\n  current methods fail to provide accurate and interpretable clinical risk at human-relevant exposure.\n  We profiled >100,000 unique molecules in primary human hepatocytes (PHHs) using a multiplexed\n  cytotoxicity assay with high content imaging & two biochemical assays (LDH & Realtime Glo/MT-Glo).\n  We train in silico models to predict dose-dependent responses for >10 distinct cell stress and death\n  features from the images solely from 2D molecular structure (SMILES string).\n  Our in silico features & thousands of clinical data points are used to train an in silico clinical risk\n  assessment model that outperforms industry-leading in vitro assays in accuracy & interpretability.\nid: sot\nteaser: sot.png\nvenue: 'SOT, 2025'\nvenuelong: Society of Toxicology Annual Meeting, Poster\nyear: '2025'\nmonth: March\nauthors:\n  - name: Katherine Titterton\n  - name: Daniil Boiko\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Alex Bäuerle\n  - name: Akshit Tyagi\n  - name: Shahin Saneinejad\n  - name: Alex Beatson\n  - name: Brandon White\nbibtex: >-\n  @article{titterton2025accurate,\n    title={Accurate and interpretable in silico clinical risk assessment for drug-induced liver injury (DILI) from molecular structure},\n    author={Titterton, Katherine L and Boiko, Daniil A and Cabrera, {\\`A}ngel A and B{\\\"a}uerle, Alex and Tyagi, Akshit and Saneinejad, Shahin and Beatson, Alex and White, Brandon},\n    year={2025},\n  }\n\npdf: /axiom-sot.pdf\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/cytotox.yml">{"status":200,"statusText":"","headers":{},"body":"title: Cell Painting for cytotoxicity and mode-of-action analysis in primary human hepatocytes\nabstract: >-\n  High-throughput, human-relevant approaches for predicting chemical toxicity are urgently needed for better decision-making in human health. Here, we apply image-based profiling (the Cell Painting assay) and two cytotoxicity assays (metabolic and membrane damage readouts) to primary human hepatocytes after exposure to eight concentrations of 1085 compounds that include pharmaceuticals, pesticides, and industrial chemicals with known liver toxicity-related outcomes. Three computational methods (CellProfiler, a Cell Painting-specific convolutional neural network, and a pretrained vision transformer) were compared to extract morphology features from single cells or entire images. We used these morphology features to predict activity in the measured cytotoxicity assays, as well as in 412 curated ToxCast assays that span cytotoxicity, cell-based, and cell-free categories. We found that the morphological profiles detect compound bioactivity at lower concentrations than standard cytotoxicity assays. In supervised analyses, they predict cytotoxicity and targeted cell-based assay readouts, but not cell-free assay readouts. We also found that the various feature extraction methods performed relatively similarly and that filtering out non-bioactive or cytotoxic concentrations did not boost supervised assay prediction performance for any assay endpoint category, although it did have a large influence on unsupervised cluster analysis. We envision that image-based profiling could serve as a key component of modern safety assessment.\nid: cytotox\nteaser: cytotox.png\nvenue: 'Preprint, 2025'\nvenuelong: Preprint\nyear: '2025'\nmonth: January\nauthors:\n  - name: Jessica Ewald\n  - name: Katherine Titterton\n  - name: Alex Bäuerle\n  - name: Alex Beatson\n  - name: Daniil Boiko\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Jaime Cheah\n  - name: Beth Cimini\n  - name: Bram Gorissen\n  - name: Thouis Jones\n  - name: Konrad Karczewski\n  - name: David Rouquié\n  - name: Srijit Seal\n  - name: Erin Weisbart\n  - name: Brandon White\n  - name: Anne Carpenter\n  - name: Shantanu Singh\nbibtex: >-\n  @article{ewald2025cell,\n    title={Cell Painting for cytotoxicity and mode-of-action analysis in primary human hepatocytes},\n    author={Ewald, Jessica D and Titterton, Katherine L and B{\\\"a}uerle, Alex and Beatson, Alex and Boiko, Daniil A and Cabrera, {\\`A}ngel A and Cheah, Jaime and Cimini, Beth A and Gorissen, Bram and Jones, Thouis and others},\n    journal={bioRxiv},\n    pages={2025--01},\n    year={2025},\n    publisher={Cold Spring Harbor Laboratory}\n  }\n\npdf: 'https://www.biorxiv.org/content/10.1101/2025.01.22.634152v1.full.pdf'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/slicing.yml">{"status":200,"statusText":"","headers":{},"body":"title: Where Does My Model Underperform? A Human Evaluation of Slice Discovery Algorithms\nid: slicing\nteaser: slicing.png\nvenue: \"HCOMP'23\"\nvenuelong: AAAI Conference on Human Computation and Crowdsourcing (HCOMP)\nmonth: November\nlocation: Delft, Netherlands\nyear: '2023'\nauthors:\n  - name: Nari Johnson\n    website: 'https://njohnson99.github.io/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Gregory Plumb\n    website: 'https://gdplumb.github.io/'\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @misc{johnson2023does,\n        title={Where Does My Model Underperform? A Human Evaluation of Slice Discovery Algorithms}, \n        author={Nari Johnson and Ángel Alexander Cabrera and Gregory Plumb and Ameet Talwalkar},\n        year={2023},\n        eprint={2306.08167},\n        archivePrefix={arXiv},\n        primaryClass={cs.HC}\n  }\nabstract: >-\n  Machine learning (ML) models that achieve high average accuracy can still underperform on semantically coherent subsets (i.e. \"slices\") of data. This behavior can have significant societal consequences for the safety or bias of the model in deployment, but identifying these underperforming slices can be difficult in practice, especially in domains where practitioners lack access to group annotations to define coherent subsets of their data. Motivated by these challenges, ML researchers have developed new slice discovery algorithms that aim to group together coherent and high-error subsets of data. However, there has been little evaluation focused on whether these tools help humans form correct hypotheses about where (for which groups) their model underperforms. We conduct a controlled user study (N = 15) where we show 40 slices output by two state-of-the-art slice discovery algorithms to users, and ask them to form hypotheses about where an object detection model underperforms. Our results provide positive evidence that these tools provide some benefit over a naive baseline, and also shed light on challenges faced by users during the hypothesis formation step. We conclude by discussing design opportunities for ML and HCI researchers. Our findings point to the importance of centering users when designing and evaluating new tools for slice discovery.\npdf: 'https://arxiv.org/pdf/2306.08167.pdf'\naward: Best Paper\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/blindspots.yml">{"status":200,"statusText":"","headers":{},"body":"title: Towards a More Rigorous Science of Blindspot Discovery in Image Classification Models\nid: blindspots\nteaser: spotcheck.png\nvenue: \"TMLR\"\nvenuelong: Transactions on Machine Learning Research (TMLR)\nyear: '2023'\nauthors:\n  - name: Gregory Plumb*\n    website: 'https://gdplumb.github.io/'\n  - name: Nari Johnson*\n    website: 'https://njohnson99.github.io/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @inproceedings{plumb2023towards,\n  author = {Plumb, Gregory and Johnson, Nari and Cabrera, \\'{A}ngel Alexander and Talwalkar, Ameet},\n  title = {Towards a More Rigorous Science of Blindspot Discovery in Image Classification Models},\n  year = {2023},\n  booktitle = {Transactions on Machine Learning Research (TMLR)},\n  }\n# citation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'\nabstract: >-\n  A growing body of work studies Blindspot Discovery Methods (\"BDM\"s): methods that use an image embedding to find semantically meaningful (i.e., united by a human-understandable concept) subsets of the data where an image classifier performs significantly worse.  Motivated by observed gaps in prior work, we introduce a new framework for evaluating BDMs, SpotCheck, that uses synthetic image datasets to train models with known blindspots and a new BDM, PlaneSpot, that uses a 2D image representation.  We use SpotCheck to run controlled experiments that identify factors that influence BDM performance (e.g., the number of blindspots in a model, or features used to define the blindspot) and show that PlaneSpot is competitive with and in many cases outperforms existing BDMs.  Importantly, we validate these findings by designing additional experiments that use real image data from MS-COCO, a large image benchmark dataset.  Our findings suggest several promising directions for future work on BDM design and evaluation.  Overall, we hope that the methodology and analyses presented in this work will help facilitate a more rigorous science of blindspot discovery.\npdf: 'https://openreview.net/pdf?id=MaDvbLaBiF'\ncode: https://github.com/njohnson99/spotcheck"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/zeno.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning'\nid: zeno\nteaser: zeno.png\nvenue: CHI'23\nvenuelong: >-\n  ACM Conference on Conference on Human Factors in Computing Systems\n  (CHI)\nyear: '2023'\nmonth: May\nlocation: Hamburg, Germany\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Erica Fu\n    website: https://ericafu.me/\n  - name: Donald Bertucci\n    website: https://www.donnybertucci.com/\n  - name: Kenneth Holstein\n    website: https://www.thecoalalab.com/kenholstein\n  - name: Ameet Talwalkar\n    website: https://www.cs.cmu.edu/~atalwalk/\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\n  - name: Adam Perer\n    website: 'http://perer.org'\ncode: https://github.com/zeno-ml/zeno\nweb: http://zenoml.com\npdf: https://dl.acm.org/doi/pdf/10.1145/3544548.3581268\ncitation: https://doi.org/10.1145/3544548.3581268\nbibtex: >-\n  @inproceedings{cabrera2023zeno,\n  author = {Cabrera, \\'{A}ngel Alexander and Fu, Erica and Bertucci, Donald and Holstein, Kenneth and Talwalkar, Ameet and Hong, Jason I. and Perer, Adam},\n  title = {Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning},\n  year = {2023},\n  isbn = {9781450394215},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3544548.3581268},\n  doi = {10.1145/3544548.3581268},\n  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},\n  articleno = {419},\n  numpages = {14},\n  keywords = {visualization, testing, machine learning, evaluation},\n  location = {Hamburg, Germany},\n  series = {CHI '23}\n  }\nabstract: >-\n  Machine learning models with high accuracy on test data can still produce systematic failures, such as harmful biases and safety issues, when deployed in the real world.\n  To detect and mitigate such failures, practitioners run behavioral evaluation of their models, checking model outputs for specific types of inputs.\n  Behavioral evaluation is important but challenging, requiring practitioners to discover real-world patterns and validate systematic failures. \n  We conducted 18 semi-structured interviews with ML practitioners to better understand the challenges of behavioral evaluation and found that it is a collaborative, use-case-first process that is not adequately supported by existing task- and domain-specific tools.\n  Using these findings, we designed Zeno, a general-purpose framework for visualizing and testing AI systems across diverse use cases.\n  In four case studies with participants using Zeno on real-world models, we found that practitioners were able to reproduce previous manual analyses and discover new systematic failures.\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/behavior.yml">{"status":200,"statusText":"","headers":{},"body":"title: Improving Human-AI Collaboration with Descriptions of AI Behavior\nabstract: >-\n  People work with AI systems to improve their decision making, but often under- or over-rely on AI predictions and perform worse than they would have unassisted. To help people appropriately rely on AI aids, we propose showing them behavior descriptions, details of how AI systems perform on subgroups of instances. We tested the efficacy of behavior descriptions through user studies with 225 participants in three distinct domains: fake review detection, satellite image classification, and bird classification. We found that behavior descriptions can increase human-AI accuracy through two mechanisms: helping people identify AI failures and increasing people's reliance on the AI when it is more accurate. These findings highlight the importance of people's mental models in human-AI collaboration and show that informing people of high-level AI behaviors can significantly improve AI-assisted decision making.\nid: behavior\nteaser: behavior.png\nvenue: CSCW'23\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2023'\nmonth: October\nlocation: Minneapolis\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3579612'\nurl: 'https://doi.org/10.1145/3579612'\ndoi: '10.1145/3579612'\ncitation: 'https://dl.acm.org/doi/10.1145/3579612'\nbibtex: >-\n  @article{cabrera2022behavior,\n  author = {Cabrera, \\'{A}ngel Alexander and Perer, Adam and Hong, Jason I.},\n  title = {Improving Human-AI Collaboration With Descriptions of AI Behavior},\n  year = {2023},\n  issue_date = {April 2023},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  volume = {7},\n  number = {CSCW1},\n  url = {https://doi.org/10.1145/3579612},\n  doi = {10.1145/3579612},\n  journal = {Proc. ACM Hum.-Comput. Interact.},\n  month = {apr},\n  articleno = {136},\n  numpages = {21},\n  }\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/aiffinity.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'What Did My AI Learn? How Data Scientists Make Sense of Model Behavior'\nid: aiffinity\nteaser: aiffinity.png\nvenue: TOCHI'22\nvenuelong: >-\n  ACM Transactions on Computer-Human Interaction (TOCHI)\nyear: '2023'\nmonth: February\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Marco Tulio Ribeiro\n    website: https://homes.cs.washington.edu/~marcotcr/\n  - name: Bongshin Lee\n    website: http://bongshiny.com/\n  - name: Rob DeLine\n    website: https://www.microsoft.com/en-us/research/people/rdeline/\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Steven M. Drucker\n    website: 'https://www.microsoft.com/en-us/research/people/sdrucker/'\nabstract: >-\n  Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them.\n  Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned.\n  We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior.\n  To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design AIFinnity, a system for analyzing image-and-text models. \n  Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using AIFinnity to pick an image captioning model.\n  We found that AIFinnity's sensemaking workflow reflected participants' mental processes and enabled them to discover and validate diverse AI behaviors.\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3542921'\ncitation: 'https://dl.acm.org/doi/10.1145/3542921'\nbibtex: >-\n  @article{Cabrera2023AIfinnity,\n    author = {Cabrera, \\'{A}ngel Alexander and Tulio Ribeiro, Marco and Lee, Bongshin and Deline, Robert and Perer, Adam and Drucker, Steven M.},\n    title = {What Did My AI Learn? How Data Scientists Make Sense of Model Behavior},\n    year = {2023},\n    issue_date = {February 2023},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    volume = {30},\n    number = {1},\n    issn = {1073-0516},\n    url = {https://doi.org/10.1145/3542921},\n    doi = {10.1145/3542921},\n    journal = {ACM Trans. Comput.-Hum. Interact.},\n    month = {mar},\n    articleno = {1},\n    numpages = {27},\n  }\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/symphony.yml">{"status":200,"statusText":"","headers":{},"body":"title: 'Symphony: Composing Interactive Interfaces for Machine Learning'\nid: symphony\nteaser: symphony.png\nvenue: CHI'22\nvenuelong: >-\n  ACM Conference on Conference on Human Factors in Computing Systems\n  (CHI)\nyear: '2022'\nmonth: May\nlocation: New Orleans\nauthors:\n  - name: Ángel Alexander Cabrera*\n    website: 'https://cabreraalex.com'\n  - name: Alex Bäuerle*\n    website: https://a13x.io/\n  - name: Fred Hohman\n    website: https://fredhohman.com/\n  - name: Megan Maher\n  - name: David Koski\n  - name: Xavier Suau\n  - name: Titus Barik\n    website: https://www.barik.net/\n  - name: Dominik Moritz\n    website: https://www.domoritz.de/\nabstract: >-\n  Interfaces for machine learning (ML), information and visualizations about models or data, can help practitioners build robust and responsible ML systems.\n  Despite their benefits, recent studies of ML teams and our interviews with practitioners (n=9) showed that ML interfaces have limited adoption in practice.\n  While existing ML interfaces are effective for specific tasks, they are not designed to be reused, explored, and shared by multiple stakeholders in cross-functional teams.\n  To enable analysis and communication between different ML practitioners, we designed and implemented Symphony, a framework for composing interactive ML interfaces with task-specific, data-driven components that can be used across platforms such as computational notebooks and web dashboards.\n  We developed Symphony through participatory design sessions with 10 teams (n=31), and discuss our findings from deploying Symphony to 3 production ML projects at Apple.\n  Symphony helped ML practitioners discover previously unknown issues like data duplicates and blind spots in models while enabling them to share insights with other stakeholders.\npdf: 'https://dl.acm.org/doi/pdf/10.1145/3491102.3502102'\nvideo: 'https://www.youtube.com/watch?v=0Q3wIh3AiPs'\nbibtex: >-\n  @inproceedings{symphony,\n  author = {B\\\"{a}uerle, Alex and Cabrera, \\'{A}ngel Alexander and Hohman, Fred and Maher, Megan and Koski, David and Suau, Xavier and Barik, Titus and Moritz, Dominik},\n  title = {Symphony: Composing Interactive Interfaces for Machine Learning},\n  year = {2022},\n  isbn = {9781450391573},\n  publisher = {Association for Computing Machinery},\n  address = {New York, NY, USA},\n  url = {https://doi.org/10.1145/3491102.3502102},\n  doi = {10.1145/3491102.3502102},\n  booktitle = {CHI Conference on Human Factors in Computing Systems},\n  articleno = {210},\n  numpages = {14},\n  location = {New Orleans, LA, USA},\n  series = {CHI '22}\n  }\ncitation: 'https://dl.acm.org/doi/10.1145/3491102.3502102'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/covidcast.yml">{"status":200,"statusText":"","headers":{},"body":"title: An open repository of real-time COVID-19 indicators\ndesc: 'We created an interactive dashboard for tracking COVID-19 indicators. The\n  indicators are collected from various sources such as social media surveys\n  and testing labs, and can be used to predict or better understand factors in\n  the spread and severity of COVID-19.'\nid: covidcast\nteaser: covidcast.png\nvenue: PNAS'21\nvenuelong: Proceedings of the National Academy of Sciences (PNAS)\nyear: '2021'\nmonth: December\nauthors:\n  - name: Alex Reinhart\n  - name: Logan Brooks\n  - name: Maria Jahja\n  - name: Aaron Rumack\n  - name: Jingjing Tang\n  - name: '[et al, including Ángel Alexander Cabrera]'\nabstract: 'The COVID-19 pandemic presented enormous data challenges in the United\n  States. Policy makers, epidemiological modelers, and health researchers all\n  require up-to-date data on the pandemic and relevant public behavior,\n  ideally at fine spatial and temporal resolution. The COVIDcast API is our\n  attempt to fill this need: Operational since April 2020, it provides open\n  access to both traditional public health surveillance signals (cases,\n  deaths, and hospitalizations) and many auxiliary indicators of COVID-19\n  activity, such as signals extracted from deidentified medical claims data,\n  massive online surveys, cell phone mobility data, and internet search\n  trends. These are available at a fine geographic resolution (mostly at the\n  county level) and are updated daily. The COVIDcast API also tracks all\n  revisions to historical data, allowing modelers to account for the frequent\n  revisions and backfill that are common for many public health data sources.\n  All of the data are available in a common format through the API and\n  accompanying R and Python software packages. This paper describes the data\n  sources and signals, and provides examples demonstrating that the auxiliary\n  signals in the COVIDcast API present information relevant to tracking COVID\n  activity, augmenting traditional public health reporting and empowering\n  research and decision-making.'\npdf: 'https://www.pnas.org/content/pnas/118/51/e2111452118.full.pdf'\nbibtex: \"@article{Reinhart2021,doi = {10.1073/pnas.2111452118},url =\n  {https://doi.org/10.1073/pnas.2111452118},year = {2021},month =\n  dec,publisher = {Proceedings of the National Academy of Sciences},volume =\n  {118},number = {51},pages = {e2111452118},author = {Alex Reinhart and Logan\n  Brooks and Maria Jahja and Aaron Rumack and Jingjing Tang and Sumit Agrawal\n  and Wael Al Saeed and Taylor Arnold and Amartya Basu and Jacob Bien and\n  {'{A}}ngel A. Cabrera and Andrew Chin and Eu Jing Chua and Brian Clark and\n  Sarah Colquhoun and Nat DeFries and David C. Farrow and Jodi Forlizzi and\n  Jed Grabman and Samuel Gratzl and Alden Green and George Haff and Robin Han\n  and Kate Harwood and Addison J. Hu and Raphael Hyde and Sangwon Hyun and\n  Ananya Joshi and Jimi Kim and Andrew Kuznetsov and Wichada La Motte-Kerr and\n  Yeon Jin Lee and Kenneth Lee and Zachary C. Lipton and Michael X. Liu and\n  Lester Mackey and Kathryn Mazaitis and Daniel J. McDonald and Phillip\n  McGuinness and Balasubramanian Narasimhan and Michael P. O'Brien and Natalia\n  L. Oliveira and Pratik Patil and Adam Perer and Collin A. Politsch and\n  Samyak Rajanala and Dawn Rucker and Chris Scott and Nigam H. Shah and Vishnu\n  Shankar and James Sharpnack and Dmitry Shemetov and Noah Simon and Benjamin\n  Y. Smith and Vishakha Srivastava and Shuyi Tan and Robert Tibshirani and\n  Elena Tuzhilina and Ana Karina Van Nortwick and Val{'{e}}rie Ventura and\n  Larry Wasserman and Benjamin Weaver and Jeremy C. Weiss and Spencer Whitman\n  and Kristin Williams and Roni Rosenfeld and Ryan J. Tibshirani},title = {An\n  open repository of real-time {COVID}-19 indicators},journal = {Proceedings\n  of the National Academy of Sciences}}\"\ncitation: 'https://www.pnas.org/doi/10.1073/pnas.2111452118'\ncode: 'https://github.com/cmu-delphi/www-covidcast'\nweb: 'https://delphi.cmu.edu/covidcast/'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/deblinder.yml">{"status":200,"statusText":"","headers":{},"body":"title: Discovering and Validating AI Errors With Crowdsourced Failure Reports\ndesc: >-\n  We introduce failure reports, end-user descriptions of how an AI system\n  failed, and show how they can be used to detect systematic AI errors. We\n  also designed and implemented Deblinder, a visual analytics system data\n  scientists can use to explore and validate patterns from failure reports. In\n  a user study, we found that data scientists found consistent failures and\n  that collecting data from those failure areas significantly increased model\n  performance.\nid: deblinder\nteaser: deblinder.jpg\nvenue: CSCW'21\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2021'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Abraham Druck\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\n  - name: Adam Perer\n    website: 'http://perer.org'\nabstract: >-\n  AI systems can fail to learn important behaviors, leading to real-world\n  issues like safety concerns and biases. Unfortunately, discovering these\n  systematic failures often requires significant developer attention, from\n  hypothesizing potential edge cases to collecting evidence and validating\n  patterns. To scale and streamlinethis process, we introduce failure reports,\n  end-user descriptions of how or why a model failed, and show how developers\n  can use them to detect AI errors. We also design and implement Deblinder, a\n  visual analytics system for synthesizing failure reports that developers can\n  use to discover and validate systematic failures. In semi-structured\n  interviews and think-aloud studies with 10 AI practitioners, we explore the\n  affordances of the Deblinder system and the applicability of failure reports\n  in real-world settings. Lastly, we show how collecting additional data from\n  the groups identified by developers can improve model performance.\npdf: 'https://cabreraalex.com/deblinder.pdf'\nbibtex: >-\n  @article{cabrera2021deblinder,author = {Cabrera, '{A}ngel Alexander and\n  Druck, Abraham J. and Hong, Jason I. and Perer, Adam},title = {Discovering\n  and Validating AI Errors With Crowdsourced Failure Reports},year =\n  {2021},issue_date = {October 2021},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {5},number = {CSCW2},url =\n  {https://doi.org/10.1145/3479569},doi = {10.1145/3479569},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = oct,articleno = {425},numpages = {22}}\ncitation: 'https://dl.acm.org/doi/10.1145/3479569'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/expo.yml">{"status":200,"statusText":"","headers":{},"body":"title: Regularizing Black-box Models for Improved Interpretability\nid: expo\nteaser: expo.png\nvenue: NeurIPS'20\nvenuelong: Conference on Neural Information Processing Systems (NeurIPS)\nyear: '2020'\nmonth: December\nlocation: Vancouver\nauthors:\n  - name: Gregory Plumb\n    website: 'https://gdplumb.github.io/'\n  - name: Maruan Al-Shedivat\n    website: 'https://www.cs.cmu.edu/~mshediva/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org/'\n  - name: Eric Xing\n    website: 'http://www.cs.cmu.edu/~epxing/'\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @inproceedings{plumb2020expo,\n  author = {Plumb, Gregory and Al-Shedivat, Maruan and Cabrera, \\'{A}ngel Alexander and Perer, Adam and Xing, Eric and Talwalkar, Ameet},\n  title = {Regularizing Black-Box Models for Improved Interpretability},\n  year = {2020},\n  isbn = {9781713829546},\n  publisher = {Curran Associates Inc.},\n  address = {Red Hook, NY, USA},\n  booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},\n  articleno = {883},\n  numpages = {11},\n  location = {Vancouver, BC, Canada},\n  series = {NIPS'20}\n  }\ncitation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'\nabstract: >-\n  Most of the work on interpretable machine learning has focused on designing\n  either inherently interpretable models, which typically trade-off accuracy\n  for interpretability, or post-hoc explanation systems, which tend to lack\n  guarantees about the quality of their explanations. We explore a\n  hybridization of these approaches by directly regularizing a black-box model\n  for interpretability at training time - a method we call ExpO. We find that\n  post-hoc explanations of an ExpO-regularized model are consistently more\n  stable and of higher fidelity, which we show theoretically and support\n  empirically. Critically, we also find ExpO leads to explanations that are\n  more actionable, significantly more useful, and more intuitive as supported\n  by a user study.\npdf: 'https://dl.acm.org/doi/pdf/10.5555/3495724.3496607'\ncode: 'https://github.com/GDPlumb/ExpO'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/confusion.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  Designing Alternative Representations of Confusion Matrices to Support\n  Non-Expert Public Understanding of Algorithm Performance\ndesc: >-\n  We studied how non-experts use confusion matrices to understand machine\n  learning models. We then developed and tested multiple alternative\n  representations of model performance, finding that contextualized and\n  direcitonal representations are the most useful modifications for improving\n  understanding.\nid: confusion\nteaser: representations.png\nvenue: CSCW'20\nvenuelong: >-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2020'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Hong Shen\n    website: 'https://www.andrew.cmu.edu/user//hongs/'\n  - name: Haojian Jin\n    website: 'http://shift-3.com/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Haiyi Zhu\n    website: 'https://haiyizhu.com/'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\nbibtex: >-\n  @article{shen2020confusion,author = {Shen, Hong and Jin, Haojian and\n  Cabrera, '{A}ngel Alexander and Perer, Adam and Zhu, Haiyi and Hong, Jason\n  I.},title = {Designing Alternative Representations of Confusion Matrices to\n  Support Non-Expert Public Understanding of Algorithm Performance},year =\n  {2020},issue_date = {October 2020},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {4},number = {CSCW2},url =\n  {https://doi.org/10.1145/3415224},doi = {10.1145/3415224},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = {oct},articleno = {153},numpages = {22}}\nabstract: >-\n  Ensuring effective public understanding of algorithmic decisions that are\n  powered by machine learning techniques has become an urgent task with the\n  increasing deployment of AI systems into our society. In this work, we\n  present a concrete step toward this goal by redesigning confusion matrices\n  for binary classification to support non-experts in understanding the\n  performance of machine learning models. Through interviews (n=7) and a\n  survey (n=102), we mapped out two major sets of challenges lay people have\n  in understanding standard confusion matrices: the general terminologies and\n  the matrix design. We further identified three sub-challenges regarding the\n  matrix design, namely, confusion about the direction of reading the data,\n  layered relations and quantities involved. We then conducted an online\n  experiment with 483 participants to evaluate how effective a series of\n  alternative representations target each of those challenges in the context\n  of an algorithm for making recidivism predictions. We developed three levels\n  of questions to evaluate users' objective understanding. We assessed the\n  effectiveness of our alternatives for accuracy in answering those questions,\n  completion time, and subjective understanding. Our results suggest that (1)\n  only by contextualizing terminologies can we significantly improve users'\n  understanding and (2) flow charts, which help point out the direction of\n  reading the data, were most useful in improving objective understanding. Our\n  findings set the stage for developing more intuitive and generally\n  understandable representations of the performance of machine learning\n  models.\npdf: 'https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf'\ncitation: 'https://dl.acm.org/doi/10.1145/3415224'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/fairvis.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  FairVis: Visual Analytics for Discovering Intersectional Bias in Machine\n  Learning\ndesc: >-\n  FairVis is a visual analytics system that enables data scientists to find\n  potential biases in their machine learning models. It allows users to split\n  their data into subgroups of different features to see how vulnerable groups\n  are performing for various fairness metrics. Additionally, it suggests\n  groups that may be underperforming and can find similar groups.\nid: fairvis\nteaser: fairvis.png\nvenue: VIS'19\nvenuelong: IEEE Conference on Visual Analytics Science and Technology (VAST)\nyear: '2019'\nmonth: October\nlocation: 'Vancouver, Canada'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Will Epperson\n    website: 'http://willepperson.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Minsuk Kahng\n    website: 'https://minsuk.com'\n  - name: Jamie Morgenstern\n    website: 'http://jamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @INPROCEEDINGS{cabrera2019fairvis, author={Á. A. {Cabrera} and W. {Epperson}\n  and F. {Hohman} and M. {Kahng} and J. {Morgenstern} and D. H. {Chau}},\n  booktitle={2019 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)}, title={FAIRVIS: Visual Analytics for Discovering Intersectional\n  Bias in Machine Learning}, year={2019}, volume={}, number={},\n  pages={46-56},doi={10.1109/VAST47406.2019.8986948}}\nabstract: >-\n  The growing capability and accessibility of machine learning has led to its\n  application to many real-world domains and data about people. Despite the\n  benefits algorithmic systems may bring, models can reflect, inject, or\n  exacerbate implicit and explicit societal biases into their outputs,\n  disadvantaging certain demographic subgroups. Discovering which biases a\n  machine learning model has introduced is a great challenge, due to the\n  numerous definitions of fairness and the large number of potentially\n  impacted subgroups. We present FairVis, a mixed-initiative visual analytics\n  system that integrates a novel subgroup discovery technique for users to\n  audit the fairness of machine learning models. Through FairVis, users can\n  apply domain knowledge to generate and investigate known subgroups, and\n  explore suggested and similar subgroups. FairVis' coordinated views enable\n  users to explore a high-level overview of subgroup performance and\n  subsequently drill down into detailed investigation of specific subgroups.\n  We show how FairVis helps to discover biases in two real datasets used in\n  predicting income and recidivism. As a visual analytics system devoted to\n  discovering bias in machine learning, FairVis demonstrates how interactive\n  visualization may help data scientists and the general public understand and\n  create more equitable algorithmic systems.\nweb: 'https://poloclub.github.io/FairVis/'\ncode: 'https://github.com/poloclub/FairVis'\nblog: >-\n  https://medium.com/@cabreraalex/fairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f\npdf: 'https://arxiv.org/abs/1904.05419'\nvideo: 'https://vimeo.com/showcase/6524122/video/368702211'\ncitation: 'https://ieeexplore.ieee.org/document/8986948'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/gemini.yml">{"status":200,"statusText":"","headers":{},"body":"title: An In-depth Look at Gemini's Language Abilities\nabstract: >-\n  The recently released Google Gemini class of models are the first to comprehensively report results that rival the OpenAI GPT series across a wide variety of tasks. In this paper, we do an in-depth exploration of Gemini's language abilities, making two contributions. First, we provide a third-party, objective comparison of the abilities of the OpenAI GPT and Google Gemini models with reproducible code and fully transparent results. Second, we take a closer look at the results, identifying areas where one of the two model classes excels. We perform this analysis over 10 datasets testing a variety of language abilities, including reasoning, answering knowledge-based questions, solving math problems, translating between languages, generating code, and acting as instruction-following agents. From this analysis, we find that Gemini Pro achieves accuracy that is close but slightly inferior to the corresponding GPT 3.5 Turbo on all tasks that we benchmarked. We further provide explanations for some of this under-performance, including failures in mathematical reasoning with many digits, sensitivity to multiple-choice answer ordering, aggressive content filtering, and others. We also identify areas where Gemini demonstrates comparably high performance, including generation into non-English languages, and handling longer and more complex reasoning chains. Code and data for reproduction can be found at this https URL\nid: gemini\nteaser: gemini.png\nvenue: 'Preprint, 2023'\nvenuelong: Preprint\nyear: '2023'\nmonth: December\nauthors:\n  - name: Syeda Nahida Akter\n    website: https://snat1505027.github.io/\n  - name: Zichun Yu\n    website: https://yuzc19.github.io/\n  - name: Aashiq Muhamed\n    website: https://www.lti.cs.cmu.edu/people/222228510/aashiq-muhamed\n  - name: Tianyue Ou\n    website: https://www.lti.cs.cmu.edu/people/222228510/aashiq-muhamed\n  - name: Alex Bäuerle\n    website: https://a13x.io\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Krish Dholakia\n    website: https://github.com/BerriAI/litellm\n  - name: Chenyan Xiong\n    website: https://www.cs.cmu.edu/~cx/\n  - name: Graham Neubig\n    website: https://photron.com\nbibtex: >-\n  @misc{akter2023indepth,\n      title={An In-depth Look at Gemini's Language Abilities}, \n      author={Syeda Nahida Akter and Zichun Yu and Aashiq Muhamed and Tianyue Ou and Alex Bäuerle and Ángel Alexander Cabrera and Krish Dholakia and Chenyan Xiong and Graham Neubig},\n      year={2023},\n      eprint={2312.11444},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n  }\npdf: 'https://arxiv.org/pdf/2312.11444.pdf'\ncode: 'https://github.com/neulab/gemini-benchmark'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/spotcheck.yml">{"status":200,"statusText":"","headers":{},"body":"title: Evaluating Systemic Error Detection Methods using Synthetic Images\nid: spotcheck\nteaser: spotcheck.png\nvenue: \"Workshop, ICML'22\"\nvenuelong: ICML - Workshop on Spurious Correlations, Invariance and Stability\nyear: '2022'\nmonth: July\nlocation: Baltimore, MD\nauthors:\n  - name: Gregory Plumb\n    website: 'https://gdplumb.github.io/'\n  - name: Nari Johnson\n    website: 'https://njohnson99.github.io/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Marco Tulio Ribeiro\n    website: https://homes.cs.washington.edu/~marcotcr/\n  - name: Ameet Talwalkar\n    website: 'https://www.cs.cmu.edu/~atalwalk/'\nbibtex: >-\n  @inproceedings{plumb2020expo,\n  author = {Plumb, Gregory and Johnson, Nari and Cabrera, \\'{A}ngel Alexander and Ribeiro, Marco Tulio and Talwalkar, Ameet},\n  title = {Evaluating Systemic Error Detection Methods using Synthetic Images},\n  year = {2022},\n  booktitle = {Workshop on Spurious Correlations, Invariance and Stability at International Conference on Machine Learning},\n  }\n# citation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'\nabstract: >-\n  We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.\npdf: 'https://arxiv.org/pdf/2207.04104.pdf'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/publics.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  \"Public(s)-in-the-Loop\": Facilitating Deliberation of Algorithmic Decisions\n  in Contentious Public Policy Domains\ndesc: >-\n  We introduce a framework for thinking about how to better involve human\n  influence in algorithmic decision-making of contentious public policy\n  issues.\nid: publics\nteaser: publics-in-loop.png\nvenue: \"Workshop, CHI'20\"\nvenuelong: CHI - Fair & Responsible AI Workshop\nyear: '2020'\nmonth: May\nlocation: 'Hawaii, USA'\nauthors:\n  - name: Hong Shen\n    website: 'https://www.andrew.cmu.edu/user//hongs/'\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Adam Perer\n    website: 'http://perer.org'\n  - name: Jason I. Hong\n    website: 'http://www.cs.cmu.edu/~jasonh/'\nbibtex: >-\n  @article{hong2020publics, title={\"Public(s)-in-the-Loop\": Facilitating\n  Deliberation of Algorithmic Decisions in Contentious Public Policy Domains},\n  author={Shen, Hong and Cabrera, Ángel Alexander and Perer, Adam and Hong,\n  Jason}, journal={Fair & Responsible AI Workshop at CHI}, year={2020}}\nabstract: >-\n  This position paper offers a framework to think about how to better involve\n  human influence in algorithmic decision-making of contentious public policy\n  issues. Drawing from insights in communication literature, we introduce a\n  ``public(s)-in-the-loop'' approach and enumerates three features that are\n  central to this approach: publics as plural political entities, collective\n  decision-making through deliberation, and the construction of publics. It\n  explores how these features might advance our understanding of stakeholder\n  participation in AI design in contentious public policy domains such as\n  recidivism prediction. Finally, it sketches out part of a research agenda\n  for the HCI community to support this work.\npdf: 'https://www.andrew.cmu.edu/user/hongs/files/20_chi_workshop_publics.pdf'\nworkshop: 'http://fair-ai.owlstown.com/'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/subgroup-gen.yml">{"status":200,"statusText":"","headers":{},"body":"title: >-\n  Discovery of Intersectional Bias in Machine Learning Using Automatic\n  Subgroup Generation\ndesc: >-\n  We introduce a method for automatically generating subgroups of instances\n  that a model may be biased against. The instances are first clustered and\n  then described by their dominating features. By ranking and sorting the\n  groups by their performance metrics (F1, accuracy, etc. ) users can spot\n  groups that are underperforming.\nid: subgroup-gen\nteaser: iclr.png\nvenue: \"Workshop, ICLR'19\"\nvenuelong: ICLR - Debugging Machine Learning Models Workshop (Debug ML)\nyear: '2019'\nmonth: May\nlocation: 'New Orleans, Louisiana, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Minsuk Kahng\n    website: 'https://minsuk.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Jamie Morgenstern\n    website: 'http://jamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @article{cabrera2019discovery, title={Discovery of Intersectional Bias in\n  Machine Learning Using Automatic Subgroup Generation}, author={Cabrera,\n  Ángel Alexander and Kahng, Minsuk and Hohman, Fred and Morgenstern, Jamie\n  and Chau, Duen Horng}, journal={Debugging Machine Learning Models Workshop\n  (Debug ML) at ICLR}, year={2019}}\nabstract: >-\n  As machine learning is applied to data about people, it is crucial to\n  understand how learned models treat different demographic groups. Many\n  factors, including what training data and class of models are used, can\n  encode biased behavior into learned outcomes. These biases are often small\n  when considering a single feature (e.g., sex or race) in isolation, but\n  appear more blatantly at the intersection of multiple features. We present\n  our ongoing work of designing automatic techniques and interactive tools to\n  help users discover subgroups of data instances on which a model\n  underperforms. Using a bottom-up clustering technique for subgroup\n  generation, users can quickly find areas of a dataset in which their models\n  are encoding bias. Our work presents some of the first user-focused,\n  interactive methods for discovering bias in machine learning models.\npdf: 'https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_3.pdf'\nworkshop: 'https://debug-ml-iclr2019.github.io/'\n"}</script>
			<script type="application/json" data-sveltekit-fetched data-url="/pubs/interactive-classification.yml">{"status":200,"statusText":"","headers":{},"body":"title: Interactive Classification for Deep Learning Interpretation\ndesc: >-\n  We developed an interactive system that allows users to modify images to\n  explore the weaknesses and strenghts of image classification models. Users\n  can 'inpaint' or remove parts of an image and see how it impacts their\n  classification.\nid: interactive-classification\nteaser: interactive.png\nvenue: \"Demo, CVPR'18\"\nvenuelong: CVPR - Demo\nyear: '2018'\nmonth: June\nlocation: 'Salt Lake City, Utah, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https://cabreraalex.com'\n  - name: Fred Hohman\n    website: 'https://fredhohman.com'\n  - name: Jason Lin\n    website: 'http://jlin.xyz'\n  - name: Duen Horng (Polo) Chau\n    website: 'https://poloclub.github.io/polochau/'\nbibtex: >-\n  @article{cabrera2018interactive, title={Interactive Classification for Deep\n  Learning Interpretation}, author={Cabrera, Ángel Alexander and Hohman, Fred\n  and Lin, Jason and Chau, Duen Horng}, journal={Demo, IEEE Conference on\n  Computer Vision and Pattern Recognition (CVPR)}, year={2018},\n  organization={IEEE}}\nabstract: >-\n  We present an interactive system enabling users to manipulate images to\n  explore the robustness and sensitivity of deep learning image classifiers.\n  Using modern web technologies to run in-browser inference, users can remove\n  image features using inpainting algorithms to obtain new classifications in\n  real time. This system allows users to compare and contrast what image\n  regions humans and machine learning models use for classification.\npdf: 'https://arxiv.org/abs/1806.05660'\nvideo: 'https://www.youtube.com/watch?v=llub5GcOF6w'\nweb: 'https://cabreraalex.github.io/interactive-classification'\ncode: 'https://github.com/poloclub/interactive-classification'\n"}</script>
			<script>
				{
					__sveltekit_1pl2n4k = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					const data = [null,null,null];

					Promise.all([
						import("./_app/immutable/entry/start.DNKtDXHz.js"),
						import("./_app/immutable/entry/app.CRPD1fuC.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-L44Q80F4Q9"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag() {
				dataLayer.push(arguments);
			}
			gtag('js', new Date());
			gtag('config', 'G-L44Q80F4Q9');
		</script>
	</body>
</html>
