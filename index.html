<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="description" content="" />
		<link rel="icon" href="/favicon.png" />
		<link
			rel="stylesheet"
			href="https://unpkg.com/purecss@1.0.1/build/pure-min.css"
			integrity="sha384-oAOxQR6DkCoMliIh8yFnu25d7Eq/PHS21PClpwjOTeU2jRSq11vu66rf90/cZr47"
			crossorigin="anonymous"
		/>
		<link rel="stylesheet" href="https://unpkg.com/purecss@1.0.1/build/grids-responsive-min.css" />
		<link rel="stylesheet" href="/global.css" />

		<link
			rel="stylesheet"
			href="https://use.fontawesome.com/releases/v5.0.12/css/all.css"
			integrity="sha384-G0fIWCsCzJIMAVNQPfjH08cyYaUtMwjJwqiRKxxE/rx96Uroj1BtIQ6MLJuheaO9"
			crossorigin="anonymous"
		/>
		<link rel="preconnect" href="https://fonts.googleapis.com" />
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
		<link
			href="https://fonts.googleapis.com/css2?family=Barlow:wght@300;400;600&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css?family=Open+Sans:400|Roboto:900,400"
			rel="stylesheet"
		/>
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
	<link rel="stylesheet" href="/_app/assets/pages/index.svelte-6dcfd776.css">
	<link rel="stylesheet" href="/_app/assets/Sidebar-23c3a463.css">
	<link rel="stylesheet" href="/_app/assets/Social-57662bc7.css">
	<link rel="stylesheet" href="/_app/assets/Intro-3fc60a44.css">
	<link rel="stylesheet" href="/_app/assets/Footer-6c39282c.css">
	<link rel="modulepreload" href="/_app/start-10571ed1.js">
	<link rel="modulepreload" href="/_app/chunks/vendor-e42abbb2.js">
	<link rel="modulepreload" href="/_app/layout.svelte-c11e8583.js">
	<link rel="modulepreload" href="/_app/pages/index.svelte-47b8d243.js">
	<link rel="modulepreload" href="/_app/chunks/Sidebar-9a2f91c6.js">
	<link rel="modulepreload" href="/_app/chunks/Social-06eee5ec.js">
	<link rel="modulepreload" href="/_app/chunks/Intro-d88055b2.js">
	<link rel="modulepreload" href="/_app/chunks/Footer-b9186261.js">
	<link rel="modulepreload" href="/_app/chunks/Links-b1d10364.js">
			<script type="module">
				import { start } from "/_app/start-10571ed1.js";
				start({
					target: document.querySelector("#svelte"),
					paths: {"base":"","assets":""},
					session: {},
					route: true,
					spa: false,
					trailing_slash: "never",
					hydrate: {
						status: 200,
						error: null,
						nodes: [
							import("/_app/layout.svelte-c11e8583.js"),
						import("/_app/pages/index.svelte-47b8d243.js")
						],
						url: new URL("http://prerender/"),
						params: {}
					}
				});
			</script>
	</head>
	<body>
		<div id="svelte">


<div class="pure-g" id="main-container"><div id="sidebar" class="pure-u-1 pure-u-md-1-4"><div id="padded-sidebar" class="svelte-nsfz3q"><a href="/"><img width="170px" src="images/profile.jpg" alt="profile"></a>
		<h1 id="name" class="svelte-nsfz3q"><span class="color svelte-nsfz3q">Ángel </span>
			<br>
			<span class="color red svelte-nsfz3q">Alex</span>
			<span class="color svelte-nsfz3q">ander</span>
			<br>
			<span class="color red svelte-nsfz3q">Cabrera</span></h1>
		<div id="social">
	<a href="mailto:cabrera@cmu.edu"><h3 class="svelte-k1wkez"><i class="fas fa-envelope"></i>   cabrera@cmu.edu</h3></a>
	<a href="https://twitter.com/a_a_cabrera"><h3 class="svelte-k1wkez"><i class="fab fa-twitter social-icon"></i>   @a_a_cabrera</h3></a>
		<a href="https://cabreraalex.medium.com/"><h3 class="svelte-k1wkez"><i class="fab fa-medium-m"></i>   Blog</h3></a>
	<a href="https://github.com/cabreraalex"><h3 class="svelte-k1wkez"><i class="fab fa-github"></i>   GitHub</h3></a>
	<a href="https://scholar.google.com/citations?user=r89SDm0AAAAJ&hl=en"><h3 class="svelte-k1wkez"><i class="fas fa-graduation-cap"></i>  Google Scholar</h3></a>
</div>
		<a href="/cv"><button class="cv">CV (web)</button></a>
		<a href="/cv.pdf"><button class="cv">CV (pdf)</button></a></div>
</div>
	<div id="content" class="pure-u-1 pure-u-md-3-4"><div id="padded-content"><div id="intro"><h2 id="hello" class="svelte-v38s0x">Hi! You can call me <span class="name">Alex</span></h2>
				<p class="svelte-2epx34">I am a PhD student in the
  <a href="https://hcii.cmu.edu/">Human-Computer Interaction Institute (HCII)
  </a>
  at Carnegie Mellon University, advised by
  <a href="http://perer.org">Adam Perer</a>
  and
  <a href="http://www.cs.cmu.edu/~jasonh/">Jason Hong.</a>
  I work on human-centered data science, specifically in applying techniques from
  HCI and visualization to help people better understand and improve their machine
  learning models. I am supported by an
  <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship.</a></p>

<p class="svelte-2epx34">Before CMU, I graduated with a B.S. in Computer Science from Georgia Tech
  where I worked with
  <a href="https://www.cc.gatech.edu/~dchau/">Polo Chau</a>
  and
  <a href="http://jamiemorgenstern.com/">Jamie Morgenstern.</a>
  I&#39;ve spent time at
  
  Apple AI/ML, Microsoft Research, and a few summers as a software engineering intern
  at
  
  Google working on Google Maps, Cloud Dataflow, and Android Auto.
</p></div>
			<div id="news" class="sect"><div class="inline svelte-v38s0x"><h2 class="header svelte-v38s0x">News</h2>
					<p><a class="right-all" href="/news">see all</a></p></div>
				<hr>
				<div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">May 17, 2021</p>
						<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->First week at &#127822;!<!-- HTML_TAG_END --></p>
					</div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">May 18, 2020</p>
						<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->Excited to spend the summer doing a ~virtual~ internship at Microsoft Research with <a href='https://www.microsoft.com/en-us/research/people/sdrucker/'>Steven Drucker</a> at the <a href='https://www.microsoft.com/en-us/research/group/vida/'>VIDA group.</a><!-- HTML_TAG_END --></p>
					</div><div class="news-item pure-g"><p class="pure-u-1 pure-u-md-1-5 date">April 23, 2020</p>
						<p class="item pure-u-1 pure-u-md-4-5"><!-- HTML_TAG_START -->Our system for visualizing indicators of COVID symptoms <a href='https://covidcast.cmu.edu/'>is live!</a><!-- HTML_TAG_END --></p>
					</div></div>
			<div id="pubs" class="sect"><div class="inline svelte-v38s0x"><h2 class="header svelte-v38s0x">Refereed Publications</h2>
					</div>
				<hr>
				<div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/covidcast"><div style="background-image: url(images/covidcast.png)" class="thumb" alt="teaser"></div></a>
							<div><p class="venue">PNAS&#39;21</p>
							</div></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/covidcast"><h4 class="paper-title">An open repository of real-time COVID-19 indicators</h4></a>
								<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='javascript:void(0);'>Alex Reinhart</a>, <a class=' author' href='javascript:void(0);'>Logan Brooks</a>, <a class=' author' href='javascript:void(0);'>Maria Jahja</a>, <a class=' author' href='javascript:void(0);'>Aaron Rumack</a>, <a class=' author' href='javascript:void(0);'>Jingjing Tang</a>, <a class='me author' href='javascript:void(0);'>[et al, including Ángel Alexander Cabrera]</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://www.pnas.org/content/pnas/118/51/e2111452118.full.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://www.doi2bib.org/bib/https://doi.org/10.1073/pnas.2111452118"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="https://cabreraalex.com/paper/covidcast"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/deblinder"><div style="background-image: url(images/deblinder.jpg)" class="thumb" alt="teaser"></div></a>
							<div><p class="venue">CSCW&#39;21</p>
							</div></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/deblinder"><h4 class="paper-title">Discovering and Validating AI Errors With Crowdsourced Failure Reports</h4></a>
								<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='javascript:void(0);'>Abraham Druck</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason Hong</a>, <a class=' author' href='http://perer.org'>Adam Perer</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://cabreraalex.com/deblinder.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3479569"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="https://cabreraalex.com/paper/deblinder"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/expo"><div style="background-image: url(images/expo.png)" class="thumb" alt="teaser"></div></a>
							<div><p class="venue">NeurIPS&#39;20</p>
							</div></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/expo"><h4 class="paper-title">Regularizing Black-box Models for Improved Interpretability</h4></a>
								<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://gdplumb.github.io/'>Gregory Plumb</a>, <a class=' author' href='https://www.cs.cmu.edu/~mshediva/'>Maruan Al-Shedivat</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org/'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~epxing/'>Eric Xing</a>, <a class=' author' href='https://www.cs.cmu.edu/~atalwalk/'>Ameet Talwalkar</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://arxiv.org/pdf/1902.06787.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://proceedings.neurips.cc/paper/10607-/bibtex"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	<a href="https://github.com/GDPlumb/ExpO"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="https://cabreraalex.com/paper/expo"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/confusion"><div style="background-image: url(images/representations.png)" class="thumb" alt="teaser"></div></a>
							<div><p class="venue">CSCW&#39;20</p>
							</div></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/confusion"><h4 class="paper-title">Designing Alternative Representations of Confusion Matrices to Support Non-Expert Public Understanding of Algorithm Performance</h4></a>
								<p class="authors"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class=' author' href='http://shift-3.com/'>Haojian Jin</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='https://haiyizhu.com/'>Haiyi Zhu</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason Hong</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://www.andrew.cmu.edu/user//hongs/files/CM_CSCW2020.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://dl.acm.org/doi/10.1145/3415224"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	
	
	
	
	
	
	<a href="https://cabreraalex.com/paper/confusion"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/fairvis"><div style="background-image: url(images/fairvis.png)" class="thumb" alt="teaser"></div></a>
							<div><p class="venue">VIS&#39;19</p>
							</div></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/fairvis"><h4 class="paper-title">FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning</h4></a>
								<p class="authors"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://willepperson.com'>Will Epperson</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://arxiv.org/abs/1904.05419"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	<a href="https://ieeexplore.ieee.org/document/8986948"><button class="entry-link"><i class="fas fa-book"></i>
				<p>BibTex</p></button></a>
	<a href="https://medium.com/@cabreraalex/fairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f"><button class="entry-link"><i class="fab fa-medium"></i>
				<p>Blog</p></button></a>
	
	<a href="https://vimeo.com/showcase/6524122/video/368702211"><button class="entry-link"><i class="fab fa-youtube"></i>
				<p>Video</p></button></a>
	<a href="https://poloclub.github.io/FairVis/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Demo</p></button></a>
	<a href="https://github.com/poloclub/FairVis"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="https://cabreraalex.com/paper/fairvis"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div></div>
			<div id="pubs" class="sect"><div class="inline svelte-v38s0x"><h2 class="header svelte-v38s0x">Workshops, Demos, Posters, and Preprints</h2></div>
				<hr>
				<div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/publics"><div style="background-image: url(images/publics-in-loop.png)" class="thumb" alt="teaser"></div></a>
							<p class="venue">Workshop, CHI&#39;20</p></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/publics"><h4 class="paper-title">&quot;Public(s)-in-the-Loop&quot;: Facilitating Deliberation of Algorithmic Decisions in Contentious Public Policy Domains</h4></a>
								<p class="author"><!-- HTML_TAG_START --><a class=' author' href='https://www.andrew.cmu.edu/user//hongs/'>Hong Shen</a>, <a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='http://perer.org'>Adam Perer</a>, <a class=' author' href='http://www.cs.cmu.edu/~jasonh/'>Jason Hong</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://www.andrew.cmu.edu/user/hongs/files/20_chi_workshop_publics.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	<a href="http://fair-ai.owlstown.com/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Workshop</p></button></a>
	
	
	
	
	<a href="https://cabreraalex.com/paper/publics"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/subgroup-gen"><div style="background-image: url(images/iclr.png)" class="thumb" alt="teaser"></div></a>
							<p class="venue">Workshop, ICLR&#39;19</p></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/subgroup-gen"><h4 class="paper-title">Discovery of Intersectional Bias in Machine Learning Using Automatic Subgroup Generation</h4></a>
								<p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://minsuk.com'>Minsuk Kahng</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jamiemorgenstern.com'>Jamie Morgenstern</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_3.pdf"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	<a href="https://debug-ml-iclr2019.github.io/"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Workshop</p></button></a>
	
	
	
	
	<a href="https://cabreraalex.com/paper/subgroup-gen"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div><div class="pure-g pub"><div class="thumb-box pure-u-1 pure-u-md-1-3 svelte-v38s0x"><a href="/paper/interactive-classification"><div style="background-image: url(images/interactive.png)" class="thumb" alt="teaser"></div></a>
							<p class="venue">Demo, CVPR&#39;18</p></div>
						<div class="pure-u-1 pure-u-md-2-3"><div class="padded"><a href="/paper/interactive-classification"><h4 class="paper-title">Interactive Classification for Deep Learning Interpretation</h4></a>
								<p class="author"><!-- HTML_TAG_START --><a class='me author' href='https://cabreraalex.com'>Ángel Alexander Cabrera</a>, <a class=' author' href='https://fredhohman.com'>Fred Hohman</a>, <a class=' author' href='http://jlin.xyz'>Jason Lin</a>, <a class=' author' href='https://poloclub.github.io/polochau/'>Duen Horng (Polo) Chau</a><!-- HTML_TAG_END --></p>
								</div>
							<div class="buttons"><a href="https://arxiv.org/abs/1806.05660"><button class="entry-link"><i class="fas fa-file-pdf"></i>
				<p>PDF</p></button></a>
	
	
	
	<a href="https://www.youtube.com/watch?v=llub5GcOF6w"><button class="entry-link"><i class="fab fa-youtube"></i>
				<p>Video</p></button></a>
	<a href="https://cabreraalex.github.io/interactive-classification"><button class="entry-link"><i class="fas fa-globe"></i>
				<p>Demo</p></button></a>
	<a href="https://github.com/poloclub/interactive-classification"><button class="entry-link"><i class="fab fa-github"></i>
				<p>Code</p></button></a>
	
	<a href="https://cabreraalex.com/paper/interactive-classification"><button class="entry-link"><i class="fas fa-globe"></i>
			<p>Website</p></button></a></div></div>
					</div></div></div>
		<div class="footer svelte-1ynsxf6"><p id="copyright">© 2022 Ángel Alexander Cabrera - Made with
		<a href="https://svelte.dev">SvelteKit</a></p>
</div></div>
</div>

<script type="application/json" data-type="svelte-data" data-url="/news.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"- date: 'May 17, 2021'\n  news: First week at &#127822;!\n- date: 'May 18, 2020'\n  news: \u003E-\n    Excited to spend the summer doing a ~virtual~ internship at Microsoft\n    Research with \u003Ca\n    href='https:\u002F\u002Fwww.microsoft.com\u002Fen-us\u002Fresearch\u002Fpeople\u002Fsdrucker\u002F'\u003ESteven\n    Drucker\u003C\u002Fa\u003E at the \u003Ca\n    href='https:\u002F\u002Fwww.microsoft.com\u002Fen-us\u002Fresearch\u002Fgroup\u002Fvida\u002F'\u003EVIDA group.\u003C\u002Fa\u003E\n- date: 'April 23, 2020'\n  news: \u003E-\n    Our system for visualizing indicators of COVID symptoms \u003Ca\n    href='https:\u002F\u002Fcovidcast.cmu.edu\u002F'\u003Eis live!\u003C\u002Fa\u003E\n- date: 'March 5, 2020'\n  news: \u003E-\n    Thanks to the Data Stories podcast for having Yongsu Ahn and me on their\n    show to talk about \u003Ca\n    href='https:\u002F\u002Fdatastori.es\u002F156-fairness-in-machine-learning-with-yongsu-ahn-and-alex-cabrera\u002F'\u003Efairness\n    and machine learning.\u003C\u002Fa\u003E\n- date: 'July 23, 2019'\n  news: We will be presenting FairVis as a conference paper at VIS'19.\n- date: 'May 6, 2019'\n  news: \u003E-\n    Our work on discovering intersectional bias was accepted to the \u003Ca\n    href='https:\u002F\u002Fdebug-ml-iclr2019.github.io\u002F'\u003EDebugging Machine Learning\n    Models workshop\u003C\u002Fa\u003E at ICLR'19 in New Orleans.\n- date: 'April 10, 2019'\n  news: \"Named a \u003Ca href='https:\u002F\u002Fwww.nsfgrfp.org\u002F'\u003ENSF Graduate Research Fellow.\u003C\u002Fa\u003E\"\n- date: 'April 3, 2019'\n  news: \u003E-\n    Excited to be starting my PhD in Human-Computer Interaction at Carnegie\n    Mellon in Fall 2019!\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/covidcast.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: An open repository of real-time COVID-19 indicators\ndesc: 'We created an interactive dashboard for tracking COVID-19 indicators. The\n  indicators are collected from various sources such as social media surveys\n  and testing labs, and can be used to predict or better understand factors in\n  the spread and severity of COVID-19.'\nid: covidcast\nteaser: covidcast.png\nvenue: PNAS'21\nvenuelong: Proceedings of the National Academy of Sciences (PNAS)\nyear: '2021'\nmonth: December\nauthors:\n  - name: Alex Reinhart\n  - name: Logan Brooks\n  - name: Maria Jahja\n  - name: Aaron Rumack\n  - name: Jingjing Tang\n  - name: '[et al, including Ángel Alexander Cabrera]'\nabstract: 'The COVID-19 pandemic presented enormous data challenges in the United\n  States. Policy makers, epidemiological modelers, and health researchers all\n  require up-to-date data on the pandemic and relevant public behavior,\n  ideally at fine spatial and temporal resolution. The COVIDcast API is our\n  attempt to fill this need: Operational since April 2020, it provides open\n  access to both traditional public health surveillance signals (cases,\n  deaths, and hospitalizations) and many auxiliary indicators of COVID-19\n  activity, such as signals extracted from deidentified medical claims data,\n  massive online surveys, cell phone mobility data, and internet search\n  trends. These are available at a fine geographic resolution (mostly at the\n  county level) and are updated daily. The COVIDcast API also tracks all\n  revisions to historical data, allowing modelers to account for the frequent\n  revisions and backfill that are common for many public health data sources.\n  All of the data are available in a common format through the API and\n  accompanying R and Python software packages. This paper describes the data\n  sources and signals, and provides examples demonstrating that the auxiliary\n  signals in the COVIDcast API present information relevant to tracking COVID\n  activity, augmenting traditional public health reporting and empowering\n  research and decision-making.'\npdf: 'https:\u002F\u002Fwww.pnas.org\u002Fcontent\u002Fpnas\u002F118\u002F51\u002Fe2111452118.full.pdf'\nbibtex: \"@article{Reinhart2021,doi = {10.1073\u002Fpnas.2111452118},url =\n  {https:\u002F\u002Fdoi.org\u002F10.1073\u002Fpnas.2111452118},year = {2021},month =\n  dec,publisher = {Proceedings of the National Academy of Sciences},volume =\n  {118},number = {51},pages = {e2111452118},author = {Alex Reinhart and Logan\n  Brooks and Maria Jahja and Aaron Rumack and Jingjing Tang and Sumit Agrawal\n  and Wael Al Saeed and Taylor Arnold and Amartya Basu and Jacob Bien and\n  {'{A}}ngel A. Cabrera and Andrew Chin and Eu Jing Chua and Brian Clark and\n  Sarah Colquhoun and Nat DeFries and David C. Farrow and Jodi Forlizzi and\n  Jed Grabman and Samuel Gratzl and Alden Green and George Haff and Robin Han\n  and Kate Harwood and Addison J. Hu and Raphael Hyde and Sangwon Hyun and\n  Ananya Joshi and Jimi Kim and Andrew Kuznetsov and Wichada La Motte-Kerr and\n  Yeon Jin Lee and Kenneth Lee and Zachary C. Lipton and Michael X. Liu and\n  Lester Mackey and Kathryn Mazaitis and Daniel J. McDonald and Phillip\n  McGuinness and Balasubramanian Narasimhan and Michael P. O'Brien and Natalia\n  L. Oliveira and Pratik Patil and Adam Perer and Collin A. Politsch and\n  Samyak Rajanala and Dawn Rucker and Chris Scott and Nigam H. Shah and Vishnu\n  Shankar and James Sharpnack and Dmitry Shemetov and Noah Simon and Benjamin\n  Y. Smith and Vishakha Srivastava and Shuyi Tan and Robert Tibshirani and\n  Elena Tuzhilina and Ana Karina Van Nortwick and Val{'{e}}rie Ventura and\n  Larry Wasserman and Benjamin Weaver and Jeremy C. Weiss and Spencer Whitman\n  and Kristin Williams and Roni Rosenfeld and Ryan J. Tibshirani},title = {An\n  open repository of real-time {COVID}-19 indicators},journal = {Proceedings\n  of the National Academy of Sciences}}\"\ncitation: 'https:\u002F\u002Fwww.doi2bib.org\u002Fbib\u002Fhttps:\u002F\u002Fdoi.org\u002F10.1073\u002Fpnas.2111452118'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/deblinder.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: Discovering and Validating AI Errors With Crowdsourced Failure Reports\ndesc: \u003E-\n  We introduce failure reports, end-user descriptions of how an AI system\n  failed, and show how they can be used to detect systematic AI errors. We\n  also designed and implemented Deblinder, a visual analytics system data\n  scientists can use to explore and validate patterns from failure reports. In\n  a user study, we found that data scientists found consistent failures and\n  that collecting data from those failure areas significantly increased model\n  performance.\nid: deblinder\nteaser: deblinder.jpg\nvenue: CSCW'21\nvenuelong: \u003E-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2021'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Abraham Druck\n  - name: Jason Hong\n    website: 'http:\u002F\u002Fwww.cs.cmu.edu\u002F~jasonh\u002F'\n  - name: Adam Perer\n    website: 'http:\u002F\u002Fperer.org'\nabstract: \u003E-\n  AI systems can fail to learn important behaviors, leading to real-world\n  issues like safety concerns and biases. Unfortunately, discovering these\n  systematic failures often requires significant developer attention, from\n  hypothesizing potential edge cases to collecting evidence and validating\n  patterns. To scale and streamlinethis process, we introduce failure reports,\n  end-user descriptions of how or why a model failed, and show how developers\n  can use them to detect AI errors. We also design and implement Deblinder, a\n  visual analytics system for synthesizing failure reports that developers can\n  use to discover and validate systematic failures. In semi-structured\n  interviews and think-aloud studies with 10 AI practitioners, we explore the\n  affordances of the Deblindersystem and the applicability of failure reports\n  in real-world settings. Lastly, we show how collecting additional data from\n  the groups identified by developers can improve model performance.\npdf: 'https:\u002F\u002Fcabreraalex.com\u002Fdeblinder.pdf'\nbibtex: \u003E-\n  @article{cabrera2021deblinder,author = {Cabrera, '{A}ngel Alexander and\n  Druck, Abraham J. and Hong, Jason I. and Perer, Adam},title = {Discovering\n  and Validating AI Errors With Crowdsourced Failure Reports},year =\n  {2021},issue_date = {October 2021},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {5},number = {CSCW2},url =\n  {https:\u002F\u002Fdoi.org\u002F10.1145\u002F3479569},doi = {10.1145\u002F3479569},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = oct,articleno = {425},numpages = {22}}\ncitation: 'https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3479569'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/expo.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: Regularizing Black-box Models for Improved Interpretability\ndesc: \u003E-\n  We introduce a new regularization method for training deep learning models\n  that improves the stability and fidelity of post-hoc explanantion methods\n  like LIME. Through a user study we show that the regularized model\n  empirically improves the quality of explainations.\nid: expo\nteaser: expo.png\nvenue: NeurIPS'20\nvenuelong: Conference on Neural Information Processing Systems (NeurIPS)\nyear: '2020'\nmonth: December\nlocation: Vancouver\nauthors:\n  - name: Gregory Plumb\n    website: 'https:\u002F\u002Fgdplumb.github.io\u002F'\n  - name: Maruan Al-Shedivat\n    website: 'https:\u002F\u002Fwww.cs.cmu.edu\u002F~mshediva\u002F'\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Adam Perer\n    website: 'http:\u002F\u002Fperer.org\u002F'\n  - name: Eric Xing\n    website: 'http:\u002F\u002Fwww.cs.cmu.edu\u002F~epxing\u002F'\n  - name: Ameet Talwalkar\n    website: 'https:\u002F\u002Fwww.cs.cmu.edu\u002F~atalwalk\u002F'\nbibtex: \u003E-\n  @inproceedings{plumb2020expo,author = {Plumb, Gregory and Al-Shedivat,\n  Maruan and Cabrera, '{A}ngel Alexander and Perer, Adam and Xing, Eric and\n  Talwalkar, Ameet},booktitle = {Advances in Neural Information Processing\n  Systems},pages = {10526--10536},publisher = {Curran Associates, Inc.},title\n  = {Regularizing Black-box Models for Improved Interpretability},url =\n  {https:\u002F\u002Fproceedings.neurips.cc\u002Fpaper\u002F2020\u002Ffile\u002F770f8e448d07586afbf77bb59f698587-Paper.pdf},volume\n  = {33},year = {2020}}\ncitation: 'https:\u002F\u002Fproceedings.neurips.cc\u002Fpaper\u002F10607-\u002Fbibtex'\nabstract: \u003E-\n  Most of the work on interpretable machine learning has focused on designing\n  either inherently interpretable models, which typically trade-off accuracy\n  for interpretability, or post-hoc explanation systems, which tend to lack\n  guarantees about the quality of their explanations. We explore a\n  hybridization of these approaches by directly regularizing a black-box model\n  for interpretability at training time - a method we call ExpO. We find that\n  post-hoc explanations of an ExpO-regularized model are consistently more\n  stable and of higher fidelity, which we show theoretically and support\n  empirically. Critically, we also find ExpO leads to explanations that are\n  more actionable, significantly more useful, and more intuitive as supported\n  by a user study.\npdf: 'https:\u002F\u002Farxiv.org\u002Fpdf\u002F1902.06787.pdf'\ncode: 'https:\u002F\u002Fgithub.com\u002FGDPlumb\u002FExpO'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/confusion.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: \u003E-\n  Designing Alternative Representations of Confusion Matrices to Support\n  Non-Expert Public Understanding of Algorithm Performance\ndesc: \u003E-\n  We studied how non-experts use confusion matrices to understand machine\n  learning models. We then developed and tested multiple alternative\n  representations of model performance, finding that contextualized and\n  direcitonal representations are the most useful modifications for improving\n  understanding.\nid: confusion\nteaser: representations.png\nvenue: CSCW'20\nvenuelong: \u003E-\n  ACM Conference on Computer-Supported Cooperative Work and Social Computing\n  (CSCW)\nyear: '2020'\nmonth: October\nlocation: Virtual\nauthors:\n  - name: Hong Shen\n    website: 'https:\u002F\u002Fwww.andrew.cmu.edu\u002Fuser\u002F\u002Fhongs\u002F'\n  - name: Haojian Jin\n    website: 'http:\u002F\u002Fshift-3.com\u002F'\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Adam Perer\n    website: 'http:\u002F\u002Fperer.org'\n  - name: Haiyi Zhu\n    website: 'https:\u002F\u002Fhaiyizhu.com\u002F'\n  - name: Jason Hong\n    website: 'http:\u002F\u002Fwww.cs.cmu.edu\u002F~jasonh\u002F'\nbibtex: \u003E-\n  @article{shen2020confusion,author = {Shen, Hong and Jin, Haojian and\n  Cabrera, '{A}ngel Alexander and Perer, Adam and Zhu, Haiyi and Hong, Jason\n  I.},title = {Designing Alternative Representations of Confusion Matrices to\n  Support Non-Expert Public Understanding of Algorithm Performance},year =\n  {2020},issue_date = {October 2020},publisher = {Association for Computing\n  Machinery},address = {New York, NY, USA},volume = {4},number = {CSCW2},url =\n  {https:\u002F\u002Fdoi.org\u002F10.1145\u002F3415224},doi = {10.1145\u002F3415224},journal = {Proc.\n  ACM Hum.-Comput. Interact.},month = {oct},articleno = {153},numpages = {22}}\nabstract: \u003E-\n  Ensuring effective public understanding of algorithmic decisions that are\n  powered by machine learning techniques has become an urgent task with the\n  increasing deployment of AI systems into our society. In this work, we\n  present a concrete step toward this goal by redesigning confusion matrices\n  for binary classification to support non-experts in understanding the\n  performance of machine learning models. Through interviews (n=7) and a\n  survey (n=102), we mapped out two major sets of challenges lay people have\n  in understanding standard confusion matrices: the general terminologies and\n  the matrix design. We further identified three sub-challenges regarding the\n  matrix design, namely, confusion about the direction of reading the data,\n  layered relations and quantities involved. We then conducted an online\n  experiment with 483 participants to evaluate how effective a series of\n  alternative representations target each of those challenges in the context\n  of an algorithm for making recidivism predictions. We developed three levels\n  of questions to evaluate users' objective understanding. We assessed the\n  effectiveness of our alternatives for accuracy in answering those questions,\n  completion time, and subjective understanding. Our results suggest that (1)\n  only by contextualizing terminologies can we significantly improve users'\n  understanding and (2) flow charts, which help point out the direction of\n  reading the data, were most useful in improving objective understanding. Our\n  findings set the stage for developing more intuitive and generally\n  understandable representations of the performance of machine learning\n  models.\npdf: 'https:\u002F\u002Fwww.andrew.cmu.edu\u002Fuser\u002F\u002Fhongs\u002Ffiles\u002FCM_CSCW2020.pdf'\ncitation: 'https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3415224'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/fairvis.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: \u003E-\n  FairVis: Visual Analytics for Discovering Intersectional Bias in Machine\n  Learning\ndesc: \u003E-\n  FairVis is a visual analytics system that enables data scientists to find\n  potential biases in their machine learning models. It allows users to split\n  their data into subgroups of different features to see how vulnerable groups\n  are performing for various fairness metrics. Additionally, it suggests\n  groups that may be underperforming and can find similar groups.\nid: fairvis\nteaser: fairvis.png\nvenue: VIS'19\nvenuelong: IEEE Conference on Visual Analytics Science and Technology (VAST)\nyear: '2019'\nmonth: October\nlocation: 'Vancouver, Canada'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Will Epperson\n    website: 'http:\u002F\u002Fwillepperson.com'\n  - name: Fred Hohman\n    website: 'https:\u002F\u002Ffredhohman.com'\n  - name: Minsuk Kahng\n    website: 'https:\u002F\u002Fminsuk.com'\n  - name: Jamie Morgenstern\n    website: 'http:\u002F\u002Fjamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https:\u002F\u002Fpoloclub.github.io\u002Fpolochau\u002F'\nbibtex: \u003E-\n  @INPROCEEDINGS{cabrera2019fairvis, author={Á. A. {Cabrera} and W. {Epperson}\n  and F. {Hohman} and M. {Kahng} and J. {Morgenstern} and D. H. {Chau}},\n  booktitle={2019 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)}, title={FAIRVIS: Visual Analytics for Discovering Intersectional\n  Bias in Machine Learning}, year={2019}, volume={}, number={},\n  pages={46-56},doi={10.1109\u002FVAST47406.2019.8986948}}\nabstract: \u003E-\n  The growing capability and accessibility of machine learning has led to its\n  application to many real-world domains and data about people. Despite the\n  benefits algorithmic systems may bring, models can reflect, inject, or\n  exacerbate implicit and explicit societal biases into their outputs,\n  disadvantaging certain demographic subgroups. Discovering which biases a\n  machine learning model has introduced is a great challenge, due to the\n  numerous definitions of fairness and the large number of potentially\n  impacted subgroups. We present FairVis, a mixed-initiative visual analytics\n  system that integrates a novel subgroup discovery technique for users to\n  audit the fairness of machine learning models. Through FairVis, users can\n  apply domain knowledge to generate and investigate known subgroups, and\n  explore suggested and similar subgroups. FairVis' coordinated views enable\n  users to explore a high-level overview of subgroup performance and\n  subsequently drill down into detailed investigation of specific subgroups.\n  We show how FairVis helps to discover biases in two real datasets used in\n  predicting income and recidivism. As a visual analytics system devoted to\n  discovering bias in machine learning, FairVis demonstrates how interactive\n  visualization may help data scientists and the general public understand and\n  create more equitable algorithmic systems.\ndemo: 'https:\u002F\u002Fpoloclub.github.io\u002FFairVis\u002F'\ncode: 'https:\u002F\u002Fgithub.com\u002Fpoloclub\u002FFairVis'\nblog: \u003E-\n  https:\u002F\u002Fmedium.com\u002F@cabreraalex\u002Ffairvis-discovering-bias-in-machine-learning-using-visual-analytics-acbd362a3e2f\npdf: 'https:\u002F\u002Farxiv.org\u002Fabs\u002F1904.05419'\nvideo: 'https:\u002F\u002Fvimeo.com\u002Fshowcase\u002F6524122\u002Fvideo\u002F368702211'\ncitation: 'https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F8986948'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/publics.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: \u003E-\n  \"Public(s)-in-the-Loop\": Facilitating Deliberation of Algorithmic Decisions\n  in Contentious Public Policy Domains\ndesc: \u003E-\n  We introduce a framework for thinking about how to better involve human\n  influence in algorithmic decision-making of contentious public policy\n  issues.\nid: publics\nteaser: publics-in-loop.png\nvenue: \"Workshop, CHI'20\"\nvenuelong: Fair & Responsible AI Workshop at CHI\nyear: '2020'\nmonth: May\nlocation: 'Hawaii, USA'\nauthors:\n  - name: Hong Shen\n    website: 'https:\u002F\u002Fwww.andrew.cmu.edu\u002Fuser\u002F\u002Fhongs\u002F'\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Adam Perer\n    website: 'http:\u002F\u002Fperer.org'\n  - name: Jason Hong\n    website: 'http:\u002F\u002Fwww.cs.cmu.edu\u002F~jasonh\u002F'\nbibtex: \u003E-\n  @article{hong2020publics, title={\"Public(s)-in-the-Loop\": Facilitating\n  Deliberation of Algorithmic Decisions in Contentious Public Policy Domains},\n  author={Shen, Hong and Cabrera, Ángel Alexander and Perer, Adam and Hong,\n  Jason}, journal={Fair & Responsible AI Workshop at CHI}, year={2020}}\nabstract: \u003E-\n  This position paper offers a framework to think about how to better involve\n  human influence in algorithmic decision-making of contentious public policy\n  issues. Drawing from insights in communication literature, we introduce a\n  ``public(s)-in-the-loop'' approach and enumerates three features that are\n  central to this approach: publics as plural political entities, collective\n  decision-making through deliberation, and the construction of publics. It\n  explores how these features might advance our understanding of stakeholder\n  participation in AI design in contentious public policy domains such as\n  recidivism prediction. Finally, it sketches out part of a research agenda\n  for the HCI community to support this work.\npdf: 'https:\u002F\u002Fwww.andrew.cmu.edu\u002Fuser\u002Fhongs\u002Ffiles\u002F20_chi_workshop_publics.pdf'\nworkshop: 'http:\u002F\u002Ffair-ai.owlstown.com\u002F'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/subgroup-gen.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: \u003E-\n  Discovery of Intersectional Bias in Machine Learning Using Automatic\n  Subgroup Generation\ndesc: \u003E-\n  We introduce a method for automatically generating subgroups of instances\n  that a model may be biased against. The instances are first clustered and\n  then described by their dominating features. By ranking and sorting the\n  groups by their performance metrics (F1, accuracy, etc. ) users can spot\n  groups that are underperforming.\nid: subgroup-gen\nteaser: iclr.png\nvenue: \"Workshop, ICLR'19\"\nvenuelong: Debugging Machine Learning Models Workshop (Debug ML) at ICLR\nyear: '2019'\nmonth: May\nlocation: 'New Orleans, Louisiana, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Minsuk Kahng\n    website: 'https:\u002F\u002Fminsuk.com'\n  - name: Fred Hohman\n    website: 'https:\u002F\u002Ffredhohman.com'\n  - name: Jamie Morgenstern\n    website: 'http:\u002F\u002Fjamiemorgenstern.com'\n  - name: Duen Horng (Polo) Chau\n    website: 'https:\u002F\u002Fpoloclub.github.io\u002Fpolochau\u002F'\nbibtex: \u003E-\n  @article{cabrera2019discovery, title={Discovery of Intersectional Bias in\n  Machine Learning Using Automatic Subgroup Generation}, author={Cabrera,\n  Ángel Alexander and Kahng, Minsuk and Hohman, Fred and Morgenstern, Jamie\n  and Chau, Duen Horng}, journal={Debugging Machine Learning Models Workshop\n  (Debug ML) at ICLR}, year={2019}}\nabstract: \u003E-\n  As machine learning is applied to data about people, it is crucial to\n  understand how learned models treat different demographic groups. Many\n  factors, including what training data and class of models are used, can\n  encode biased behavior into learned outcomes. These biases are often small\n  when considering a single feature (e.g., sex or race) in isolation, but\n  appear more blatantly at the intersection of multiple features. We present\n  our ongoing work of designing automatic techniques and interactive tools to\n  help users discover subgroups of data instances on which a model\n  underperforms. Using a bottom-up clustering technique for subgroup\n  generation, users can quickly find areas of a dataset in which their models\n  are encoding bias. Our work presents some of the first user-focused,\n  interactive methods for discovering bias in machine learning models.\npdf: 'https:\u002F\u002Fdebug-ml-iclr2019.github.io\u002Fcameraready\u002FDebugML-19_paper_3.pdf'\nworkshop: 'https:\u002F\u002Fdebug-ml-iclr2019.github.io\u002F'\n"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/pubs/interactive-classification.yml">{"status":200,"statusText":"","headers":{"content-type":"text/yaml"},"body":"title: Interactive Classification for Deep Learning Interpretation\ndesc: \u003E-\n  We developed an interactive system that allows users to modify images to\n  explore the weaknesses and strenghts of image classification models. Users\n  can 'inpaint' or remove parts of an image and see how it impacts their\n  classification.\nid: interactive-classification\nteaser: interactive.png\nvenue: \"Demo, CVPR'18\"\nvenuelong: Demo at IEEE Computer Vision and Pattern Recognition (CVPR)\nyear: '2018'\nmonth: June\nlocation: 'Salt Lake City, Utah, USA'\nauthors:\n  - name: Ángel Alexander Cabrera\n    website: 'https:\u002F\u002Fcabreraalex.com'\n  - name: Fred Hohman\n    website: 'https:\u002F\u002Ffredhohman.com'\n  - name: Jason Lin\n    website: 'http:\u002F\u002Fjlin.xyz'\n  - name: Duen Horng (Polo) Chau\n    website: 'https:\u002F\u002Fpoloclub.github.io\u002Fpolochau\u002F'\nbibtex: \u003E-\n  @article{cabrera2018interactive, title={Interactive Classification for Deep\n  Learning Interpretation}, author={Cabrera, Ángel Alexander and Hohman, Fred\n  and Lin, Jason and Chau, Duen Horng}, journal={Demo, IEEE Conference on\n  Computer Vision and Pattern Recognition (CVPR)}, year={2018},\n  organization={IEEE}}\nabstract: \u003E-\n  We present an interactive system enabling users to manipulate images to\n  explore the robustness and sensitivity of deep learning image classifiers.\n  Using modern web technologies to run in-browser inference, users can remove\n  image features using inpainting algorithms to obtain new classifications in\n  real time. This system allows users to compare and contrast what image\n  regions humans and machine learning models use for classification.\nwebsite: 'http:\u002F\u002Ffredhohman.com\u002Fpapers\u002Finteractive-classification'\npdf: 'https:\u002F\u002Farxiv.org\u002Fabs\u002F1806.05660'\nvideo: 'https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=llub5GcOF6w'\ndemo: 'https:\u002F\u002Fcabreraalex.github.io\u002Finteractive-classification'\ncode: 'https:\u002F\u002Fgithub.com\u002Fpoloclub\u002Finteractive-classification'\n"}</script></div>
	</body>
</html>
