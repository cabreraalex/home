title: Evaluating Systemic Error Detection Methods using Synthetic Images
id: spotcheck
teaser: spotcheck.png
venue: "Workshop, ICML'22"
venuelong: ICML - Workshop on Spurious Correlations, Invariance and Stability
year: '2022'
month: July
location: Baltimore, MD
authors:
  - name: Gregory Plumb
    website: 'https://gdplumb.github.io/'
  - name: Nari Johnson
    website: 'https://njohnson99.github.io/'
  - name: Ángel Alexander Cabrera
    website: 'https://cabreraalex.com'
  - name: Marco Tulio Ribeiro
    website: https://homes.cs.washington.edu/~marcotcr/
  - name: Ameet Talwalkar
    website: 'https://www.cs.cmu.edu/~atalwalk/'
bibtex: >-
  @inproceedings{plumb2020expo,
  author = {Plumb, Gregory and Johnson, Nari and Cabrera, \'{A}ngel Alexander and Ribeiro, Marco Tulio and Talwalkar, Ameet},
  title = {Evaluating Systemic Error Detection Methods using Synthetic Images},
  year = {2022},
  booktitle = {Workshop on Spurious Correlations, Invariance and Stability at International Conference on Machine Learning},
  }
# citation: 'https://dl.acm.org/doi/10.5555/3495724.3496607'
abstract: >-
  We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.
pdf: 'https://arxiv.org/pdf/2207.04104.pdf'
